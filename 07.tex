\lecture{}

\topic{Rickart's theorem}

Let $K$ be a field and $G$ be a group. The \textbf{group algebra} $K[G]$ 
is the vector space (over $K$) with basis $\{g:g\in G\}$ 
and the algebra structure given by the multiplication
\[
	\left(\sum_{g\in G}\lambda_gg\right)\left(\sum_{h\in G}\mu_hh\right)
	=\sum_{g,h\in G}\lambda_g\mu_h(gh).
\]
Note that every element of $K[G]$ is a finite sum of the form $\sum_{g\in G}\lambda_gg$.

\begin{exercise}
\label{xc:K[G]notsimple}
    If $G$ is non-trivial, then $K[G]$ is not simple. 
\end{exercise}

\begin{exercise}
	Let $G=C_n$ be the (multiplicative) cyclic group of order $n$. Prove that 
	$K[G]\simeq K[X]/(X^n-1)$. 
\end{exercise}

\begin{exercise}
	Let $G$ be a finitely-generated torsion-free abelian group. Prove that 
	$K[G]$ is a domain. 
\end{exercise}

\begin{exercise}
	Let $G$ be a group and $H$ be a subgroup of $G$. Let $\alpha\in K[H]$. Prove that 
    $\alpha$ is invertible (resp. left zero divisor) in $K[H]$ if and only if 
	$\alpha$ is invertible (resp. left zero divisor) in
	$K[G]$.
\end{exercise}

\begin{exercise}
	Let $G$ be a group and $\alpha=\sum_{g\in G}\lambda_gg\in K[G]$.  
	The \textbf{support} of $\alpha$ is the set 
	\[
		\supp\alpha=\{g\in G:\lambda_g\ne 0\}.
	\]
	Prove that if $g\in G$, then 
	$\supp(g\alpha)=g(\supp\alpha)$ and $\supp(\alpha g)=(\supp\alpha)g$.
\end{exercise}

% El objetivo de esta sección es calcular el radical de Jacobson del álgebra de
% grupo de un grupo finito. Comenzamos con un ejemplo:

\begin{exercise}
	Let $G=C_2=\langle g\rangle\simeq\Z/2$ the (multiplicative) 
	group with two elements. Note that every element of $K[G]$ is of the form
	$a1+bg$ for some $a,b\in K$. Prove the following statements:
	\begin{enumerate}
	    \item If the characteristic of $K$ is different from two, then 
	    \[
		K[G]\to K\times K,
		\quad
		a1+bg\mapsto (a+b,a-b),
	\]
	is an algebra isomorhism. 
	\item If the characteristic of $K$ is two, then 
	\[
	K[G]\to \begin{pmatrix}
			K & K\\
			0 & K
		\end{pmatrix},
		\quad
		a1+bg\mapsto\begin{pmatrix}
			a+b & b\\
			0 & a+b
		\end{pmatrix},
	\]
	is an algebra isomorphism. 
	\end{enumerate}
\end{exercise}

Veamos otros ejemplo un poco más difíciles. La idea a utilizar es la siguiente:
Si $A$ es una $K$-álgebra y $\rho\colon G\to U(A)$ es un morfismo de grupos,
donde $U(A)$ es el grupo de unidades de $A$, entonces la función $K[G]\to A$,
$\sum_{g\in G}\lambda_gg\mapsto\sum_{g\in G}\lambda_g\rho(g)$, es un morfismo
de álgebras.

\begin{exercise}
	Let $G=C_3$ be the (multiplicative) group of three elements. Prove that
	$\R[G]\simeq\R\times\C$.
% 	Escribamos $G=\langle g:g^3=1\rangle$ y sea 
% 	\[
% 		\varphi\colon\R[G]\to\R\times\C,
% 		\quad
% 		g\mapsto (1,\omega),
% 	\]
% 	donde $\omega$ es una raíz cúbica primitiva de la unidad. Entonces
% 	$\varphi$ es inyectivo pues
% 	$0=\varphi(a1+bg+cg^2)=(a+b+c,a+b\omega+c\omega^2)$ implica que $a=b=c=0$.
% 	Luego $\varphi$ es un isomorfismo pues
% 	$\dim_\R\R[G]=\dim_\R(\R\times\C)=3$. 
\end{exercise}

\begin{exercise}
	Let $G=\langle r,s:r^3=s^2=1,\,srs=r^{-1}\rangle$ be the dihedral group of six elements. 
	Prove the following statements:
	\begin{enumerate}
	    \item $\C[G]\simeq\C\times\C\times M_2(\C)$.
	    \item $\Q[G]\simeq\Q\times\Q\times M_2(\Q)$.
	\end{enumerate}  
% 	Sea $\omega$ una raíz cúbica de la unidad y sean  
% 	\[
% 		R=\begin{pmatrix}
% 			\omega & 0\\
% 			0 & \omega^2
% 		\end{pmatrix},
% 		\quad
% 		S=\begin{pmatrix}
% 			0 & 1\\
% 			1 & 0
% 		\end{pmatrix}.
% 	\]
% 	Un cálculo sencillo muestra que $R^2=S^2=I$ y que $SRS=R^{-1}$. Sea
% 	\[
% 		\varphi\colon\C[G]\to\C\times\C\times M_2(\C),\quad
% 		r\mapsto (1,1,R),\quad
% 		s\mapsto (1,-1,S).
% 	\]
% 	Es fácil ver que $\varphi$ es un morfismo de álgebras. Veamos que es
% 	biyectivo. Como $\dim_{\C}\C[G]=\dim_{\C}(\C\times\C\times M_2(\C))=6$,
% 	basta ver que $\varphi$ es inyectivo. Si 
% 	\[
% 		\alpha=a_0+a_1r+a_2r^2+(b_0+b_1r+b_2r^2)s\in\ker\varphi,
% 	\]
% 	entonces 
% 	\[
% 		0=\varphi(\alpha)=\left(u,v,\begin{pmatrix} \alpha_{11} & \alpha_{12}\\\alpha_{21}&\alpha_{22}\end{pmatrix}\right), 
% 	\]
% 	donde
% 	\begin{align*}
% 		&u = a_0+a_1+a_2+b_0+b_1+b_2, && v = a_0+a_1+a_2-b_0-b_1-b_2,\\
% 		&\alpha_{11}=a_0+a_1\omega+a_2\omega^2, && \alpha_{12}=b_0+b_1\omega+b_2\omega^2,\\
% 		&\alpha_{21}=b_0+b_2\omega+b_1\omega^2, && \alpha_{22}=a_0+a_2\omega+a_1\omega^2.
% 	\end{align*}
% 	Un cálculo sencillo muestra que estas ecuaciones implican que
% 	$\alpha=0$ y luego $\varphi$ es inyectiva.  
\end{exercise}

We now consider the following problem. 

\begin{openproblem}
\label{Jacobson's semisimplicity problem}
Let $G$ be a group and $K$ be a field. When $J(K[G])=\{0\}$?
\end{openproblem}

As an application of Amitsur's theorem we prove that 
complex group algebras have null Jacobson radical.
This is known as 
Rickart's theorem. The original proof found by Rickart 
uses complex analysis. Here, however, 
we present an algebraic proof. 


\begin{theorem}[Rickart]
\index{Rickart's theorem}
\label{thm:Rickart}
    Let $G$ be a group. Then $J(\C[G])=\{0\}$.
\end{theorem}

To prove the theorem we need a lemma.

\begin{lemma}
Let $G$ be a group. Then $J(\C[G])$ is nil.        
\end{lemma}

\begin{proof}
    We need to show that every element of $J(\C[G])$ is nilpotent. 
    If $G$ is countable, then the result follows from Amitsur's theorem. So assume that 
    $G$ is not countable. Let $\alpha\in J(\C[G])$, say
    \[
    \alpha=\sum_{i=1}^n\lambda_ig_i,
    \]
    where $\lambda_1,\dots,\lambda_n\in\C$ and $g_1,\dots,g_n\in G$. Let $H=\langle g_1,\dots,g_n\rangle$.
    Then $g\in \C[H]$ and $H$ is countable. We claim that $g\in J(\C[H])$. Decompose
    $G$ as a disjoint union 
    \[
    G=\bigcup_\lambda x_\lambda H
    \]
    of cosets of $H$ in $G$. Then $\C[G]=\bigoplus_\lambda x_\lambda\C[H]$ and
    hence $\C[G]=\C[H]\oplus K$ for some right module $K$ over $\C[H]$. Since $\alpha\in J(\C[G])$, for each 
    $\beta\in\C[H]$ there exists $\gamma\in\C[G]$ such that 
    $\gamma(1-\beta\alpha)=1$. Write $\gamma=\gamma_1+\kappa$ for $\gamma_1\in\C[H]$ and $\kappa\in K$. Then
    \[
    1=\gamma(1-\beta\alpha)=\gamma_1(1-\beta\alpha)+\kappa(1-\beta\alpha)
    \]
    and hence $\kappa(1-\beta\alpha)\in K\cap \C[H]=\{0\}$. Since $1=\gamma_1(1-\beta\alpha)$, it follows that
    $\alpha\in J(\C[H])$ and the lemma follows from Amitsur's theorem.  
\end{proof}

We now prove the theorem. 

\begin{proof}[Proof of Theorem \ref{thm:J(C[G])=0}]
    For $\alpha=\sum_{i=1}^n\lambda_ig_i\in\C[G]$ let 
    \[
    \alpha^*=\sum_{i=1}^n\overline{\lambda_i}g_i^{-1}.
    \]
    Then $\alpha\alpha^*=0$ if and only if $\alpha=0$ and, moreover, 
    $(\alpha\beta)^*=\beta^*\alpha^*$ for all $\beta\in\C[G]$. 
    Assume that $J(\C[G])\ne\{0\}$ and let $\alpha\in J(\C[G])\setminus\{0\}$. Then
    $\beta=\alpha\alpha^*\in J(\C[G])$, as $J(\C[G])$ is an ideal of $\C[G]$. Moreover, $\beta\ne 0$, as 
    \[
    (\beta^m)^*=(\beta^*)^m=\beta^m
    \]
    for all $m\geq1$. If there exists $k\geq2$ such that $\beta^k=0$ and $\beta^{k-1}\ne 0$, then
    \[
    \beta^{k-1}\left(\beta^{k-1}\right)^*=\beta^{2k-2}=0
    \]
    and hence $\beta^{k-1}=0$, a contradiction. Thus $\beta=0$ and therefore $\alpha=0$. 
\end{proof}

To obtain a consequence of Rickart's theorem we need two lemmas. 

\begin{lemma}[Nakayama]
	\label{lem:Nakayama}
	\index{Nakayama's lemma}
	Let $R$ be a unitary ring and $M$ be a finitely generated module. If 
	$J(R)\cdot M=M$, then $M=\{0\}$.
\end{lemma}

\begin{proof}
    Since $M$ is finitely generated, we may assume that 
	$M=(x_1,\dots,x_n)$. Since $x_n\in M=J(R)\cdot M$, 
	there exist $r_1,\dots,r_n\in J(R)$ such that $x_n=r_1\cdot x_1+\cdots+r_n\cdot x_n$, that is 
	$(1-r_n)\cdot x_n=\sum_{j=1}^{n-1}r_j\cdot x_j$. 
	Since $1-r_n$ is invertible, there exists $s\in R$ such that $s(1-r_n)=1$. Thus 
	$x_n=\sum_{j=1}^{n-1}(sr_j)\cdot x_j$ 
	and hence $M=(x_1,\dots,x_{n-1})$. Repeating this procedure several times 
	one obtains $M=\{0\}$.
\end{proof}

\begin{lemma}
	\label{lem:Rickart}
	Let $\iota\colon R\to S$ be a homomorphism of unitary rings. If	
	\[
	S=\iota(R)x_1+\cdots+\iota(R)x_n,
	\]
	where each $x_j$ is such that $x_jy=yx_j$ for all $y\in\iota(R)$, then 
	$\iota(J(R))\subseteq J(S)$.
\end{lemma}

\begin{proof}
	We claim that $J=\iota(J(R))$ acts trivially on each simple $S$-module $M$.
	If is $M$ is a simple module over $S$, then, in particular, $M=S\cdot m$ for some $m\ne0$. 
	Now $M$ is a module over $R$ with $r\cdot m=\iota(r)\cdot m$. Since 
	\[
		M=S\cdot m=(\iota(R)x_1+\cdots+\iota(R)x_n)\cdot m=\iota(R)\cdot (x_1\cdot m)+\cdots+\iota(R)\cdot (x_n\cdot m),
	\]
	it follows that 
	$M$ is finitely generated as a module over $\iota(R)$. Moreover, 
	\[
	J(R)\cdot
	M=J\cdot M=\iota(J)\cdot M
	\]
	is an $S$-submodule of $M$, as 
	\[
		x_j\cdot (J\cdot M)=(x_j J)\cdot M=(J x_j)\cdot M=J\cdot (x_j\cdot M)\subseteq J\cdot M.
	\]
	Since $M\ne\{0\}$, Nakayama's lemma implies that $J(R)\cdot M\subsetneq M$. The simplicity of 
	the $S$-module $M$ implies that $J(R)\cdot M=\{0\}$.
\end{proof}

We now obtain the following consequence of Rickart's theorem. 

\begin{theorem}
	If $G$ is a group, then $J(\R[G])=0$. 
\end{theorem}

\begin{proof}
	Let $\iota\colon \R[G]\to\C[G]$ be the canonical inclusion. Since 
	\[
	\C[G]=\R[G]+i\R[G],
	\]
	Lemma~\ref{lem:Rickart} and Rickart's theorem imply that 
	$\iota(J(\R[G]))\subseteq J(\C[G])=0$. Thus $J(\R[G])=0$, as $\iota$ is injective. 
\end{proof}

We now characterize when complex group algebras 
are left artinian. For that purpose
we need a lemma. This is similar to one of the implications proved in Proposition \ref{pro:semisimple}. However,
in the arbitrary setting we are considering, we need to use Zorn's lemma. 

\begin{lemma}
    Let $M$ be a semisimple module and $N$ be a submodule. 
    Then $N$ is a direct summand.
\end{lemma}

\begin{proof}[Sketch of the proof]
    Let $M=\oplus_{i\in I}M_i$ be a direct sum of simple modules  
    and let $i\in I$. 
    Since $N\cap M_i$ is a submodule of $M_i$ and $M_i$ is simple, it follows
    that $N\cap M_i=\{0\}$ or $N\cap M_i=M_i$. If
    $N\cap M_i=M_i$ for all $i\in I$, then $N=M$ and the lemma is proved. So we may assume
    that there exists $i\in I$ such that $N\cap M_i=\{0\}$. Let $X$ be the set
    of subsets $J$ of $I$ such that $N\cap (\oplus_{j\in J}M_j)=\{0\}$. Our assumptions
    imply that $X$ is non-empty. Zorn's lemma implies the existence of 
    a maximal element $K$. Let $N_1=\oplus_{k\in K}M_k$. We claim that
    $N\oplus N_1=M$. If not, there exists $i\in I$ such that
    $M_i\not\subseteq N\oplus N_1$. The simplicity of $M_i$ implies that
    $M_i\cap (N\cap N_1)=\{0\}$, which contradicts the maximality of $K$. 
\end{proof}

A direct application of the lemma proves that
complex group algebras of infinite groups are never semisimple. 

\begin{proposition}
    \label{pro:KGsemisimple}
    If $G$ is an infinite group, then $\C[G]$ is not semisimple. 
\end{proposition}

\begin{proof}
	Assume that $R=\C[G]$ is semisimple.  Let $I$ 
	be the augmentation ideal of $R$, that is
	\[
	I=\left\{\alpha=\sum_{g\in G}\lambda_gg\in R:\sum_{g\in G}\lambda_g=0\right\}.
	\]
	By the previous lemma, 
	there exists exists a non-zero ideal $J$ such that 
	$R=I\oplus J$. Since $R$ is unitary, there exist $e\in I$ and $f\in J$ such that
	$1=e+f$. If
	$x\in I$, then $x=xe+xf$ and hence $xf=x-xe\in I\cap J=\{0\}$. Since 
	$x=xe$ for all $x\in I$, it follows that $e=e^2$. Similarly one proves
	that $f^2=f$. Moreover, $ef=0$, as $ef\in I\cap J=\{0\}$.  Since $I$ 
	is the augmentation ideal of $R$ and $If=(Re)f=R(ef)=\{0\}$, we conclude that
	$(g-1)f=0$
	for all $g\in G$, as $g-1\in I$. If $f=\sum_{h\in
	G}\lambda_hh$ (finite sum), then  
	\[
	f=gf=\sum_{h\in G}\lambda_h(gh)=\sum_{h\in
	G}\lambda_{g^{-1}h}h.
	\]
	Thus $\lambda_h=\lambda_{g^{-1}h}$ for all $g,h\in G$, a contradiction because 
	$f\ne 0$ implies that the sum that defines $f$ should be an infinite sum.
\end{proof}

% The ideal $I(G)$ used in the proof of the previous proposition 
% is known as the \textbf{augmentation ideal} 
% of $\C[G]$.

\begin{theorem}
	Let $G$ be a group. Then $\C[G]$ 
	is left artinian if and only if 
	$G$ is finite. 
\end{theorem}

\begin{proof}
    If $G$ is finite, then $\C[G]$ is left artinian because $\dim\C[G]=|G|<\infty$. So assume that 
    $G$ is infinite. By Rickart's theorem,   
	$J(\C[G])=0$. Moreover, $\C[G]$
	is not semisimple by the previous proposition. Thus
	$\C[G]$ is not left artinian by Theorem~\ref{thm:SSartin=J}.
\end{proof}

\topic{Maschke's theorem}

We now present another instance of the Jacobson semisimplicity problem.
In this case, our result is for finite groups. 

\begin{theorem}[Maschke]
\index{Maschke's theorem}
	Let $G$ be a finite group. Then $J(K[G])=0$ if and only 
	if the characteristic of $K$ is zero 
	or does not divide the order of $G$. 
\end{theorem}

\begin{proof}
	We may assume that $G=\{g_1,\dots,g_n\}$, where $g_1=1$. Let 
	\[
	\rho\colon K[G]\to K,
	\quad
	\alpha\mapsto\trace(L_{\alpha}),
	\]
	where 
	$L_{\alpha}(\beta)=\alpha\beta$. Then $\rho(g_1)=n$ and $\rho(g_i)=0$ for all
	$i\in\{2,\dots,n\}$, as $L_{g_i}(g_j)=g_{i}g_j\ne g_j$, the matrix of 
	$L_{g_i}$ in the basis $\{g_1,\dots,g_n\}$ contains zeros in the main diagonal. 

	Assume that $J=J(K[G])$ is non-zero and let 
	$\alpha=\sum_{i=1}^n\lambda_ig_i\in J\setminus\{0\}$. Without loss of generality
	we may assume that $\lambda_1\ne 0$ (if $\lambda_1=0$ there exists some 
	$\lambda_i\ne 0$ and we need to take $g_i^{-1}\alpha\in J$). Then 
	\[
		\rho(\alpha)=\sum_{i=1}^n \lambda_i\rho(g_i)=n\lambda_1.
	\]
	Since $G$ is finite, $K[G]$ is a finite-dimensional algebra and hence 
	$K[G]$ is left artinian. Since $J$ is a nilpotent ideal, 
	in particular, $\alpha$ is a nilpotent element. Then 
	$L_{\alpha}$ is nilpotent and hence $0=\rho(\alpha)=n\lambda_1$. This implies that
	the characteristic of the field $K$ divides $n$. 

	Conversely, let $K$ be a field of prime characteristic and that this primes divides 
	$n$. Let $\alpha=\sum_{i=1}^ng_i$. Since $\alpha
	g_j=g_j\alpha=\alpha$ for all $j\in\{1,\dots,n\}$, the set 
	$I=K[G]\alpha$ is an ideal of $K[G]$. Since, moreover,   
	\[
		\alpha^2=\sum_{i=1}^n g_i\alpha=n\alpha=0,
	\]
	it follows that $I$ is a nilpotent non-zero ideal. Thus $J(K[G])\ne\{0\}$, 
	as Proposition~\ref{pro:nilJ} yields $I\subseteq J(K[G])$.
\end{proof}

Since the Jacobson radical of a group algebra of a finite group contains 
every nil left ideal, the following consequence of the theorem follows immediately:

\begin{corollary}
	\label{cor:GfinitoNOnil}
	Sea $G$ un grupo finito. Entonces $K[G]$ no contiene ideales a izquierda
	nil no nulos.
\end{corollary}


% \begin{proof}
% 	Es consecuencia inmediata del teorema de Maschke ya que $J(K[G])$ contiene a
% 	todo ideal a izquierda nil.	
% \end{proof}

%\index{Anillo!semisimple}
%Recordemos que un anillo unitario $R$ se dice \textbf{semisimple} si para cada
%ideal $I$ de $R$ existe un ideal $J$ de $R$ tal que $R=I\oplus J$.
%
%%\begin{corollary}
%%	Sea $G$ un grupo finito y $K$ un cuerpo de característica coprima con el
%%	orden de $G$. Entonces $K[G]$ es semisimple.
%%\end{corollary}
%%
%%\begin{proof}
%%	
%%\end{proof}
%
%\begin{theorem}
%	Si $G$ es un grupo infinito, entonces $K[G]$ nunca es semisimple.
%\end{theorem}
%
%\begin{proof}
%	Sea $R=K[G]$ y supongamos que $R$ es semisimple.  Si $I$ es el ideal de
%	aumentación de $R$, existe un ideal no nulo $J$ de $R$ tal que $R=I\oplus
%	J$. Como $R$ es unitario, existen $e\in I$, $f\in J$ tales que $1=e+f$. Si
%	$x\in I$, entonces $x=xe+xf$ y luego $xf=x-xe\in I\cap J=\{0\}$. Como
%	entonces $x=xe$ para todo $x\in I$, en particular $e_1=e_1^2$. Análogamente
%	vemos que $e_2^2=e_2$. Además $ef=0$ pues $ef\in I\cap J=\{0\}$.  Como $I$
%	es el ideal de aumentación y $If=(Re)f=R(ef)=0$, se concluye que $(g-1)f=0$
%	para todo $g\in G$ pues $g-1\in I$. Si suponemos que $f=\sum_{h\in
%	G}\lambda_hh$, entonces 
%	\[
%	f=gf=\sum_{h\in G}\lambda_h(gh)=\sum_{h\in
%	G}\lambda_{g^{-1}h}h.
%	\]
%	Luego $\lambda_h=\lambda_{g^{-1}h}$ para todo $g,h\in G$, una contradicción
%	pues como $f\ne 0$ la suma que define a $f$ es infinita. 
%\end{proof}


\topic{Herstein's theorem}

Our aim now is to answer the following question: When
a group algebra is algebraic? 
A partial answer is given by Herstein's theorem. 

\begin{definition}
\index{Group!locally finite}
	A group $G$ is \textbf{locally finite} if every finitely generated 
	subgroup of $G$ is finite. 
\end{definition}

If $G$ is a locally finite group, then every element $g\in G$ has finite order, as
the subgroup $\langle g\rangle$ is finite because it is finitely generated.

\begin{example}
    Every finite group is locally finite
\end{example}

\begin{example}
    The group $\Z$ is not locally finite because it is torsion-free.
\end{example}

\begin{example}
\label{Pr\"ufer's group}
	Let $p$ be a prime number. 
	The \textbf{Pr\"ufer's group}  
	\[
		\Z(p^{\infty})=\{z\in\C:z^{p^n}=1\text{ para algún $n\in\Z_{>0}$}\}, 
	\]
	formed by of all $p$-roots of one, is locally finite. 
\end{example}

\begin{example}
	Let $X$ be an infinite set and $\Sym_X$ be the set of bijective maps $X\to
	X$ moving only finitely many elements of $X$. Then 
	$\Sym_X$ is locally finite.
\end{example}

\begin{proposition}
\label{pro:exact_LI}
	Let $G$ be a group and $N$ be a normal subgroup of $G$. If $N$ and $G/N$
	are locally finite, then $G$ is locally finite.
\end{proposition}

\begin{proof}
	Let $\pi\colon G\to G/N$ be the canonical map and $\{g_1,\dots,g_n\}$ be a finite subset of $G$. 
	Since $G/N$ is locally finite, the subgroup $Q$ of $G/N$ generated by 
	$\pi(g_1),\dots,\pi(g_n)$ is finite, say
	\[
		Q=\{\pi(g_1),\dots,\pi(g_n),\pi(g_{n+1}),\dots,\pi(g_m)\}.
	\]
	For each $i,j\in\{1,\dots,n\}$ there exist $u_{ij}\in N$ and 
	$k\in\{1,\dots,m\}$ uch that $g_ig_j=u_{ij}g_k$. Let $U$ be the subgroup of $G$
	generated by $\{u_{ij}:1\leq i,j\leq n\}$. Since $N$ is locally finite, $U$ is finite. Moreover, since 
	each $g_ig_jg_l$ can be written as 
	\[
		g_ig_jg_l=u_{ij}g_kg_l=u_{ij}u_{kl}g_t=ug_t
	\]
	for some $u\in U$ and $t\in\{1,\dots,m\}$, it follows that the subgroup 
	$H$ of $G$ generated by $\{g_1,\dots,g_n\}$ is finite, as 
	$|H|\leq m|U|$. 
\end{proof}

\index{Group!solvable}
Recall that a group $G$ is
\textbf{solvable} if there exists a sequence
of subgroups 
\begin{equation}
	\label{eq:resoluble}
	\{1\}=G_0\subsetneq G_1\subsetneq \cdots\subsetneq G_n=G
\end{equation}
where each $G_i$ is normal in $G_{i+1}$ and each 
quotient $G_i/G_{i-1}$ is
abelian.
\index{Group!torsion}
A group $G$ is a \textbf{torsion} group if every element of $G$
has finite order. 

\begin{proposition}
	If $G$ is a solvable torsion group, 
	then $G$ is locally finite. 
\end{proposition}

\begin{proof}
	We proceed by induction on $n$, the length of the sequence~\eqref{eq:resoluble}. 
	If $n=1$, then $G$ is finite because it is abelian and a torsion group.
	Now assume the result holds for group with resolubility length $n-1$ and let
	$G$ be a solvable group with a sequence~\eqref{eq:resoluble}. By the inductive hypothesis, 
	the normal subgroup $G_{n-1}$ of $G$ is locally finite. Since $G/G_{n-1}$ is an abelian torsion group, 
	it is locally finite, the result now follows from Proposition \ref{pro:exact_LI}.
\end{proof}

We now prove Herstein's theorem.

\begin{theorem}[Herstein]
\index{Herstein's theorem}
	If $G$ is a locally finite group, then $K[G]$ is algebraic. Conversely, if 
	$K[G]$ is algebraic and $K$ has characteristic zero, then $G$ 
	is locally finite. 
\end{theorem}

\begin{proof}
	Assume thast $G$ is locally finite. Let $\alpha\in K[G]$. The subgroup 
	$H=\langle\supp\alpha\rangle$ is finite, as it is finitely generated. Since 
	$\alpha\in K[H]$ and $\dim_KK[H]<\infty$, the set 
	$\{1,\alpha,\alpha^2,\dots\}$ is linearly dependent. Thus $\alpha$ is
	algebraic over $K$.

	Sea $\{x_1,\dots,x_m\}$ un subconjunto finito de $G$. Si agregamos los
	inversos, podemos suponer que $\{x_1,\dots,x_m\}$ genera al subgrupo
	$H=\langle x_1,\dots,x_m\rangle$ como semigrupo. Si
	$\alpha=x_1+\dots+x_m\in K[G]$, entonces, como $\alpha$ es algebraico sobre
	$K$, 
	\[
		\alpha^{n+1}=a_0+a_1\alpha+\cdots+a_n\alpha^n
	\]
	para algún $n\geq0$ y escalares $a_0,\dots,x_n\in K$. Sea $w=x_{i_1}\cdots
	x_{i_{n+1}}\in H$ una palabra de longitud $n+1$. Observemos que existen enteros
	positivos $c_{i_1\cdots i_m}$ tales que 
	\[
		\alpha^{n+1}=(x_1+\cdots+x_m)^{n+1}
		=\sum_{\substack{{i_1+\cdots+i_m=n+1}\\{\text{$i_j$ enteros positivos}}}} c_{i_1\cdots i_m}x_1^{i_1}\cdots x_{m}^{i_m}.
	\]
	Como $K$
	es de característica cero, se concluye que $w\in\supp(\alpha^{n+1})$.  Pero
	como además $\alpha^{n+1}=\sum_{j=0}^na_j\alpha^j$, entonces
	$w\in\supp(\alpha^j)$ para algún $j\in\{0,\dots,n\}$. Demostramos entonces
	que toda palabra en las $x_j$ de longitud $n+1$ puede escribirse como una
	palabra en las $x_j$ de longitud a lo sumo $n$.  Luego $H$ es finito y
	entonces $G$ es localmente finito.
\end{proof}

\topic{Formanek's theorem}

Veremos un resultado de Formanek que puede entenderse como una generalización
del teorema de Herstein. 

\begin{exercise}
	Sea $A$ un álgebra algebraica y sea $a\in A$. Demuestre las siguientes
	afirmaciones:
	\begin{enumerate}
		\item $a$ es un divisor de cero a izquierda si y sólo si $a$ es un
			divisor de cero a derecha.
		\item $a$ es inversible a izquierda si y sólo si $a$ es inversible a
			derecha.
		\item $a$ es inversible si y sólo si $a$ no es un divisor de cero.
	\end{enumerate}
\end{exercise}

%\begin{proof}
%	Como $a$ es algebraico, podemos escribir 
%	\[
%		a^n(1+\lambda_1a+\cdots+\lambda_ma^m)=0
%	\]
%	para algún $n\geq0$ minimal y escalares $\lambda_1,\dots,\lambda_m$. Si 
%	$n>0$, entonces 
%	\[
%	b=(1+\lambda_1a+\cdots+\lambda_ma^m)a^{n-1}\ne 0
%	\]
%	cumple que $ab=ba=0$. Si $n=0$, entonces 
%	\[
%		c=-\lambda_1-\lambda_2a-\cdots-\lambda_ma^{m-1}\ne 0
%	\]
%	cumple que $ac=ca=1$. 
%\end{proof}

\begin{exercise}
	\label{exa:norma}
	Si $\alpha=\sum_{g\in G}\alpha_gg\in\C[G]$ se define $|\alpha|=\sum_{g\in
	G}|\alpha_g|\in\R$. Demuestre que valen las siguientes propiedades:
	\begin{enumerate}
		%\item $|\trace(\alpha)|\leq |\alpha|$, 
		\item $|\alpha+\beta|\leq|\alpha|+|\beta|$, y 
		\item $|\alpha\beta|\leq|\alpha||\beta|$ 
	\end{enumerate}
	para todo $\alpha,\beta\in\C[G]$.
\end{exercise}

\begin{theorem}[Formanek, primera versión]
	\label{thm:FormanekQ}
	\index{Teorema!de Formanek}
	Sea $G$ un grupo y supongamos que todo elemento de $\Q[G]$ es inversible o
	un divisor de cero. Entonces $G$ es localmente finito.
\end{theorem}

\begin{proof}
	Sea $\{x_1,\dots,x_n\}$ un subconjunto finito de $G$. Si agregamos los
	inversos, podemos suponer que $\{x_1,\dots,x_n\}$ genera al subgrupo
	$H=\langle x_1,\dots,x_n\rangle$ como semigrupo. Sea
	\[
		\alpha=\frac{1}{2n}(x_1+\cdots+x_n)\in\Q[G]
	\]

	Veamos que $1-\alpha\in\Q[G]$ es inversible. Si no, entonces es un divisor de cero. 
	Si existe $\delta\in\Q[G]$ tal que $\delta(1-\alpha)=0$, entonces
	$\delta=\delta\alpha$ y luego, como 
	\[
		|\delta|=|\delta\alpha|\leq|\delta||\alpha|=|\delta|/2,
	\]
	se concluye que $\delta=0$. Similarmente se demuestra que $(1-\alpha)\delta=0$ implica que
	$\delta=0$. 
	
	Sea $\beta=(1-\alpha)^{-1}\in\Q[G]$.  Para cada $k$ definimos 
	\[
		\gamma_k=(1+\alpha+\cdots+\alpha^k)-\beta.
	\]
	Entonces 
	\begin{align*}
		\gamma_k(1-\alpha)&=(1+\alpha+\cdots+\alpha^k-\beta)(1-\alpha)\\
		&=(1+\alpha+\cdots+\alpha^k)(1-\alpha)-\beta(1-\alpha)=-\alpha^{k+1}
	\end{align*}
	y luego 
	$\gamma_k=-\alpha^{k+1}\beta$. Como 
	\[
		|\gamma_k|=|-\alpha^{k+1}\beta|\leq|\beta||\alpha^{k+1}|=\frac{|\beta|}{2^{k+1}},
	\]
	se concluye que $\lim_{k\to\infty}|\gamma_k|=0$. 

	Para terminar veamos que $H\subseteq\supp\beta$. Si
	$H\not\subseteq\supp\beta$, sea $h\in H\setminus\supp\beta$.  Supongamos
	que $h=x_{i_1}\cdots x_{i_m}$ es una palabra de longitud $m$ en los $x_j$.
	Sea $c_j$ el coeficiente de $h$ en $\alpha^j$. Entonces $c_0+\cdots+c_k$ es
	el coeficiente de $h$ en $\gamma_k$, pero
	\[
		|\gamma_k|\geq c_0+c_1+\cdots+c_k\geq c_m>0
	\]
	para todo $k\geq m$ pues cada $c_j$ es no negativo, una contradicción pues
	demostramos que $|\gamma_k|\to 0$ si $k\to\infty$.
\end{proof}

A continuación explicaremos por qué el teorema de Formanek se considera una
generalización del teorema de Herstein. En el teorema~\ref{thm:FormanekQ} nos
concentramos en álgebras de grupo sobre los números racionales. ¿Cómo podemos
extender este resultado a álgebras de grupo sobre cuerpos de característica
cero? Para extender el cuerpo de base sobre el que se trabaja necesitamos
definir el producto tensorial de espacios vectoriales y el producto tensorial
de álgebras.

\begin{definition}
	\index{Producto tensorial!de espacios vectoriales}
	El \textbf{producto tensorial} de los $K$-espacios vectoriales $U$ y $V$ es
	el espacio vectorial cociente $K[U\times V]/T$, donde $K[U\times V]$ es el
	espacio vectorial con base $\{(u,v):u\in U,v\in V\}$ y $T$ es el subespacio
	generado por los elementos de la forma
	\[
		(\lambda u+\mu u',v)-\lambda(u,v)-\mu(u',v),\quad
		(u,\lambda v+\mu v')-\lambda(u,v)-\mu(u,v')
	\]
	para $\lambda,\mu\in K$, $u,u'\in U$ y $v,v'\in V$.
\end{definition}

El producto tensorial de $U$ y $V$ será denotado por $U\otimes_KV$ o por
$U\otimes V$ si la referencia al cuerpo $K$ puede omitirse. Dados $u\in U$
y $v\in V$ escribiremos $u\otimes v$ para denotar a la coclase $(u,v)+T$.

\begin{theorem}
\index{Producto tensorial!propiedad universal}
	Sean $U$ y $V$ espacios vectoriales.  Existe entonces una función bilineal
	$U\times V\to U\otimes V$, $(u,v)\mapsto u\otimes v$, tal que todo
	elemento de $U\otimes V$ es una suma finita de la forma
	\[
		\sum_{i=1}^N u_i\otimes v_i
	\]
	para $u_1,\dots,u_N\in U$ y $v_1,\dots,v_N\in V$. 
	Más aún, dado un espacio vectorial $W$ y una función
	bilineal $\beta\colon U\times V\to W$, existe una función lineal
	$\overline{\beta}\colon U\otimes V\to W$ tal que $\overline{\beta}(u\otimes
	v)=\beta(u,v)$ para todo $u\in U$ y $v\in V$.
\end{theorem}

\begin{proof}
	Por la definición del producto tensorial, la función 
	\[
	U\times V\to U\otimes V,\quad
	(u,v)\mapsto u\otimes v,
	\]
	es bilineal. También de la definición se deduce inmediatamente que todo
	elemento de $U\otimes V$ es una combinación lineal finita de elementos de
	la forma $u\otimes v$, donde $u\in U$ y $v\in V$. Como $\lambda(u\otimes
	v)=(\lambda u)\otimes v$ para todo $\lambda\in K$, la primera afirmación
	queda demostrada.

	Como $U\times V$ es base de $K[U\times V]$, existe una transformación lineal 
	\[
		\gamma\colon K[U\times V]\to W,\quad
	\gamma(u,v)=\beta(u,v). 
	\]
	Como $\beta$ es bilineal por hipótesis, $T\subseteq\ker\gamma$. Existe
	entonces una transformación lineal $\overline{\beta}\colon U\otimes V\to
	W$ tal que 
	\[
	\begin{tikzcd}
		K[U\times V] \arrow[r]\arrow[d] & W \\
		U\otimes V\arrow[ur, dashrightarrow]
	\end{tikzcd}
	\]
	conmuta. En particular, $\overline{\beta}(u\otimes v)=\beta(u,v)$. 
\end{proof}

\begin{exercise}
	\label{xca:tensorial_unicidad}
	Demuestre que las propiedades mencionadas en el teorema anterior
	caracterizan el producto tensorial salvo isomorfismo.
\end{exercise}

Veamos algunas propiedades del producto tensorial de espacios vectoriales. 
%Observemos
%que todo elemento de $U\otimes V$ es una suma finita
%de la forma 
%\[
%	\sum_{i=1}^N u_i\otimes v_i
%\]
%para $N\in\N$, $u_i\in U$ y $v_i\in V$. Esta expresión no es única. Vale además
%que $u\otimes 0=0=0\otimes v$ para todo $u\in U$ y $v\in V$.

\begin{lemma}
	\index{Producto tensorial!de transformaciones lineales}
	Sean $\varphi\colon U\to U'$ y $\psi\colon V\to V'$ transformaciones
	lineales. Existe entonces una única transformación lineal
	$\varphi\otimes\psi\colon U\otimes V\to U'\otimes V'$ tal que
	\[
		(\varphi\otimes\psi)(u\otimes v)=\varphi(u)\otimes\psi(v)
	\]
	para todo $u\in U$ y $v\in V$.
\end{lemma}

\begin{proof}
	Como la función $U\times V\to U\otimes V$,
	$(u,v)\mapsto\varphi(u)\otimes\psi(v)$, es bilineal, existe una
	transformación lineal $U\otimes V\to U\otimes V$, $u\otimes
	v\to\varphi(u)\otimes\psi(v)$. Luego la función
	\[
		\sum u_i\otimes v_i\mapsto\sum\varphi(u_i)\otimes\psi(v_i)
	\]
	está bien definida. 
\end{proof}

\begin{exercise}
	Demuestre las siguientes afirmaciones:
	\begin{enumerate}
		\item $(\varphi\otimes\psi)(\varphi'\otimes\psi')=(\varphi\varphi')\otimes(\psi\psi')$.
		\item Si $\varphi$ y $\psi$ son isomorfismos, entonces
			$\varphi\otimes\psi$ es un isomorfismo. 
		\item $(\lambda\varphi+\lambda'\varphi')\otimes\psi=\lambda\varphi\otimes\psi+\lambda'\varphi'\otimes\psi$.
		\item $\varphi\otimes(\lambda\psi+\lambda'\psi')=\lambda\varphi\otimes\psi+\lambda'\varphi\otimes\psi'$.
		\item Si $U\simeq U'$ y $V\simeq V'$, entonces $U\otimes V\simeq U'\otimes V'$.
	\end{enumerate}
\end{exercise}

\begin{lemma}
	Si $U$ y $V$ son espacios vectoriales, entonces 
	$U\otimes V\simeq V\otimes U$.
\end{lemma}

\begin{proof}
	Como la función $U\times V\to V\otimes U$, $(u,v)\mapsto v\otimes u$,
	existe una transformación lineal $U\otimes V\to V\otimes U$, $u\otimes
	v\mapsto v\otimes u$. Similarmente se demuestra que existe una
	transformación lineal $V\otimes U\to U\otimes V$, $v\otimes u\mapsto
	u\otimes v$. Luego $U\otimes V\simeq V\otimes U$.
\end{proof}

\begin{exercise}
	\label{xca:UxVxW}
	Demuestre que $(U\otimes V)\otimes W\simeq U\otimes(V\otimes W)$.
\end{exercise}

\begin{exercise}
	\label{xca:UxK}
	Demuestre que $U\otimes K\simeq K\simeq K\otimes U$.
\end{exercise}

\begin{lemma}
	\label{lem:U_LI}
	Sea $\{u_1,\dots,u_n\}\subseteq U$ un conjunto linealmente independiente y
	sean $v_1,\dots,v_n\in V$ tales que $\sum_{i=1}^n u_i\otimes v_i=0$.
	Entonces $v_i=0$ para todo $i\in\{1,\dots,n\}$.
\end{lemma}

\begin{proof}
	Sea $i\in\{1,\dots,n\}$ y sea $f_i\colon U\to K$, $f_i(u_j)=\delta_{ij}$.
	Como la función $U\times V\to V$, $(u,v)\mapsto f_i(u)v$, es bilineal, existe una función
	$\alpha_i\colon U\otimes V\to V$ lineal tal que $\alpha_i(u\otimes
	v)=f_i(u)v$. Luego
	\[
		v_i=\sum_{j=1}^n\alpha_i(u_j\otimes v_j)=\alpha_i\left(\sum_{j=1}^nu_j\otimes v_j\right)=0.
	\]
\end{proof}

\begin{exercise}
	\label{xca:uxv=0}
	Demuestre que si $u\otimes v=0$ y $v\ne 0$, entonces $u=0$.
\end{exercise}

\begin{theorem}
	Si $\{u_i:i\in I\}$ es una base de $U$ y $\{v_j:j\in J\}$ es una base de
	$V$, entonces $\{u_i\otimes v_j:i\in I,j\in J\}$ es una base de $U\otimes
	V$.
\end{theorem}

\begin{proof}
	Los $u_i\otimes v_j$ forman un conjunto de generadores pues  
	si $u=\sum_i\lambda_iu_i$ y $v=\sum_j\mu_jv_j$, entonces
	$u\otimes v=\sum_{i,j}\lambda_i\mu_ju_i\otimes v_j$. 
	Veamos ahora que los $u_i\otimes v_j$ son linealmente independientes. Para
	eso, queremos ver que cualquier subconjunto finito de los $u_i\otimes v_j$
	es linealmente independiente. Si $\sum_k\sum_l\lambda_{kl}u_{i_k}\otimes
	v_{j_l}=0$, entonces
	$0=\sum_{k}u_{i_k}\otimes\left(\sum_{l}\lambda_{kl}v_{j_l}\right)$ y luego,
	como los $u_{i_k}$ son linealmente indepentientes, el lema~\ref{lem:U_LI}
	implica que $\sum_{l}\lambda_{kl}v_{j_l}=0$. Luego $\lambda_{kl}=0$ para
	todo $k,l$ pues los $v_{j_l}$ son linealmente independientes.
\end{proof}

El teorema anterior implica inmediatamente que si $U$ y $V$ son espacios
vectoriales de dimensión finita entonces
\[
	\dim(U\otimes V)=(\dim U)(\dim V).
\]

\begin{corollary}
	Si $\{u_i:i\in I\}$ es base de $U$, entonces todo elemento de $U\otimes V$
	se escribe unívocamente como una suma finita $\sum_{i}u_i\otimes v_i$.
\end{corollary}

\begin{proof}
	Sabemos que todo elemento de $U\otimes V$ es una suma finita
	$\sum_i x_i\otimes y_i$, donde $x_i\in U$ y $y_i\in V$. Si escribimos 
	$x_i=\sum_j\lambda_{ij}u_j$, entonces
	\[
		\sum_i x_i\otimes y_i=\sum_i\left(\sum_j\lambda_{ij}u_j\right)\otimes y_i		
		=\sum_j u_j\otimes\left(\sum_i\lambda_{ij}y_i\right).
	\]
\end{proof}

%\begin{corollary}
%	Todo elemento no nulo de $U\otimes V$ puede escribirse como una suma finita
%	$\sum_{i=1}^N u_i\otimes v_i$ para un conjuntos $\{u_i:1\leq i\leq
%	N\}\subseteq U$ y $\{v_i:1\leq i\leq N\}\subseteq V$ linealmente
%	independientes.
%\end{corollary}
%
%\begin{proof}
%	tomar $N$ minimal	
%\end{proof}

\index{Producto tensorial!de álgebras}
El siguiente lema nos permite definir el \textbf{producto tensorial de
álgebras}.

\begin{lemma}
	Si $A$ y $B$ son álgebras, entonces $A\otimes B$ es un álgebra con el
	producto
	\[
		(a\otimes b)(x\otimes y)=ax\otimes by.
	\]
\end{lemma}

\begin{proof}
	Para $x\in A$, $y\in B$ consideramos $R_x\otimes R_y\in\End_K(A\otimes B)$.
	Como la función $A\times B\to\End_K(A\otimes B)$, $(x,y)\mapsto R_x\otimes
	R_y$, es bilineal, existe una función lineal $\varphi\colon A\otimes
	B\to\End_K(A\otimes B)$, $\varphi(x\otimes y)=R_x\otimes R_y$. Para $u,v\in A\otimes B$ definimos
	\[
		uv=\varphi(v)(u).
	\]
	Esta operación es bilineal pues por ejemplo
	\[
		u(v+w)=\varphi(v+w)(u)=(\varphi(v)+\varphi(w))(u)=\varphi(v)(u)+\varphi(w)(u)=uv+uw.
	\]
	Además
	$(a\otimes b)(x\otimes y)=\varphi(x\otimes y)(a\otimes b)=(R_x\otimes R_y)(a\otimes b)=ax\otimes by$.
	Un cálculo sencillo muestra que este producto es asociativo.
\end{proof}

\begin{exercise}
	Demuestre que para álgebras valen las siguientes afirmaciones:
	\begin{enumerate}
		\item $A\otimes B\simeq B\otimes A$.
		\item $(A\otimes B)\otimes C\simeq A\otimes(B\otimes C)$.
		\item $A\otimes K\simeq A\simeq K\otimes A$.
		\item Si $A\otimes A'$ y $B\otimes B'$ entonces $A\otimes B\simeq A'\otimes B'$.
	\end{enumerate}
\end{exercise}

Veamos algunos ejemplos:

\begin{proposition}
	Si $G$ y $H$ son grupos, entonces $K[G]\otimes K[H]\simeq K[G\times H]$.
\end{proposition}

\begin{proof}
	Sabemos que $\{g\otimes h:g\in G,h\in H\}$ es una base de $K[G]\otimes K[H]$ y que
	$G\times H$ es una base de $K[G\times H]$. Tenemos entonces un isomorfismo lineal 
	\[
	K[G]\otimes K[H]\to K[G\times H], 
	\quad 
	g\otimes h\mapsto (g,h),
	\]
	que además es multiplicativo. Luego $K[G]\otimes K[H]\simeq K[G\times H]$
	como álgebras.
\end{proof}

\begin{proposition}
	Si $A$ es un álgebra, entonces $A\otimes K[X]\simeq A[X]$.	
\end{proposition}

\begin{proof}
	Todo elemento de $A\otimes K[X]$ se escribe unívocamente como una suma
	finita de la forma $\sum a_i\otimes X^i$. Un cálculo sencillo muestra que
	$A\otimes K[X]\mapsto A[X]$, $\sum a_i\otimes X^i\mapsto \sum a_iX^i$, es
	un isomorfismo de álgebras.
\end{proof}

\begin{exercise}
	Demuestre que si $A$ es un álgebra, $A\otimes M_n(K)\simeq M_n(A)$. En
	particular, $M_n(K)\otimes M_m(K)\simeq M_{nm}(K)$.
\end{exercise}

\index{Extensión de escalares}
Estos últimos dos ejemplos son casos particulares de una construcción
importante que involucra productos tensoriales y se conoce como
\textbf{extensión de escalares}.

\begin{theorem}
	Sea $A$ un álgebra sobre $K$ y sea $E$ una extensión de $K$. Entonces
	$A^E=E\otimes_KA$ es un álgebra sobre $E$ con respecto a la multiplicación
	por escalares dada por
	\[
		\lambda(\mu\otimes a)=(\lambda\mu)\otimes a,
	\]
	para $\lambda,\mu\in E$ y $a\in A$.
\end{theorem}

\begin{proof}
	Sea $\lambda\in E$. Como la función $E\times A\to E\otimes_KA$,
	$(\mu,a)\mapsto (\lambda\mu)\otimes a$, es $K$-bilineal, existe una
	transformación lineal $E\otimes_KA\to E\otimes_KA$, $\mu\otimes a\mapsto
	(\lambda\mu)\otimes a$. Queda bien definida entonces la multiplicación por
	escalares y además 
	\[
	\lambda(u+v)=\lambda u+\lambda v
	\]
	para $\lambda\in E$ y $u,v\in E\otimes_KA$. Un cálculo directo muestra que además 
	\[
	(\lambda+\mu)u=\lambda u+\mu u,
	\quad
	(\lambda\mu)u=\lambda(\mu u),
	\quad
	\lambda(uv)=(\lambda u)v=u(\lambda v)
	\]
	valen para todo $u,v\in E\otimes_KA$ y $\lambda,\mu\in E$.
\end{proof}

\begin{exercise}
	Demuestre que valen las siguientes afirmaciones:
	\begin{enumerate}
		\item $1\otimes A$ es una subálgebra de $A^E$ isomorfa a $A$.
		\item Si $\{a_i:i\in I\}$ es base de $A$, entonces $\{1\otimes a_i:i\in
			I\}$ es base de $A^E$.
	\end{enumerate}
\end{exercise}

\begin{exercise}
	Demuestre que si $G$ es un grupo y $K$ es un subcuerpo de $E$, entonces
	$E\otimes_K K[G]\simeq E[G]$.
\end{exercise}

Estamos en condiciones de demostrar el teorema de Formanek:

\begin{theorem}[Formanek]
	\index{Teorema!de Formanek}
	Sea $K$ un cuerpo de característica cero y sea $G$ un grupo. Si todo
	elemento de $K[G]$ es inversible o un divisor de cero, entonces $G$ es
	localmente finito.
\end{theorem}

\begin{proof}
	Como $K$ es de característica cero, $\Q\subseteq K$ y $K[G]\simeq
	K\otimes_{\Q}\Q[G]$. Todo $\beta\in K\otimes_{\Q}\Q[Q]$ se escribe
	unívocamente como 
	\[
		\beta=1\otimes\beta_0+\sum k_i\otimes\beta_i,
	\]
	donde $\{1,k_1,k_2,\dots,\}$ es una base de $K$ como $\Q$-espacio
	vectorial. Sea $\alpha\in\Q[G]$ y sea $\beta\in K[G]$ tal que $\alpha\beta=1$. Como entonces 
	\[
	1\otimes 1=(1\otimes\alpha)\beta=1\otimes \alpha\beta_0+\sum k_i\otimes \alpha\beta_i,
	\]
	la unicidad de la escritura nos dice que $\alpha\beta_0=1$. De la misma
	forma, si $\alpha\beta=0$, entonces $\alpha\beta_j=0$ para todo $j$. Luego,
	como todo $\alpha\in\Q[G]$ es inversible o un divisor de cero, el resultado
	se obtiene al usar el teorema~\ref{thm:FormanekQ} de Formanek para $\Q$.
\end{proof}

% \section*{Rickart's theorem}

% En esta sección vamos a demostrar que para cualquier grupo $G$ el radical de
% Jacobson de $\C[G]$ es cero. Demostraremos también que el radical de Jacobson
% de $\R[G]$ es cero.

% \begin{definition}
% 	\index{Anillo!con involución}
% 	\index{Involución!de un anillo}
% 	Sea $R$ un anillo. Una \textbf{involución} del anillo $R$ es un morfismo
% 	aditivo $R\to R$, $x\mapsto x^*$, tal que $x^{**}=x$ y $(xy)^*=y^*x^*$ para
% 	todo $x,y\in R$.
% \end{definition}

% De la definición se deduce inmediatamente que si $R$ es unitario, entonces
% $1^*=1$.

% \begin{example}
% 	La conjugación $z\mapsto\overline{z}$ es una involución de $\C$.
% \end{example}

% \begin{example}
% 	La trasposición $X\mapsto X^T$ es una involución del
% 	anillo $M_n(K)$.
% \end{example}

% \begin{example}
% 	Sea $G$ un grupo. Entonces
% 	$\left(\sum_{g\in G}\alpha_gg\right)^*=\sum_{g\in G}\overline{\alpha_g}g^{-1}$ 
% 	es una involución de $\C[G]$.
% \end{example}

% Dado un grupo $G$, se define la \textbf{traza} de un elemento
% $\alpha=\sum_{g\in G}\alpha_gg\in K[G]$ como $\trace(\alpha)=\alpha_1$. Es
% fácil ver que $\trace\colon K[G]\to K$, $\alpha\mapsto\trace(\alpha)$ es una
% función $K$-lineal tal que $\trace(\alpha\beta)=\trace(\beta\alpha)$.

% \begin{exercise}
% 	Sea $G$ un grupo finito y $K$ un cuerpo tal que su característica no divide al orden de $G$.
% 	Demuestre las siguientes afirmaciones:
% 	\begin{enumerate}
% 		\item Si $\alpha\in K[G]$ es nilpotente, entonces $\trace(\alpha)=0$.
% 		\item Si $\alpha\in K[G]$ es idempotente, entonces $\trace(\alpha)=\dim
% 			K[G]\alpha/|G|$.
% 	\end{enumerate}
% \end{exercise}

% \begin{exercise}
% 	Demuestre que 
% 	$\langle\alpha,\beta\rangle=\trace(\alpha\beta^*)$, $\alpha,\beta\in\C[G]$, 
% 	define un producto interno en $\C[G]$.
% \end{exercise}

% \begin{lemma}
% 	\label{lem:algebraico}
% 	Sea $G$ un grupo. Si $J(\C[G])\ne 0$, entonces existe $\alpha\in J(\C[G])$ tal que 
% 	$\trace(\alpha^{2^m})\in\R_{\geq1}$ 
% 	para todo $m\geq1$.
% \end{lemma}

% \begin{proof}
% 	Sea $\alpha=\sum_{g\in G}\alpha_gg\in\C[G]$. Entonces	
% 	\[
% 		\trace(\alpha^*\alpha)
% 		=\sum_{g\in G}\overline{\alpha_g}\alpha_g
% 		=\sum_{g\in G}|\alpha_g|^2\geq|\alpha_1|^2
% 		=|\trace(\alpha)|^2.
% 	\]
% 	Al usar esta fórmula para algún $\alpha$ tal que $\alpha^*=\alpha$ y usar
% 	inducción se obtiene que $\trace(\alpha^{2^m})\geq|\trace(\alpha)|^{2^m}$
% 	para todo $m\geq1$. 

% 	Sea $\beta=\sum_{g\in G}\beta_gg\in J(\C[G])$ tal que $\beta\ne0$. Como
% 	$\trace(\beta^*\beta)=\sum_{g\in G}|\beta_g|^2\ne0$ y $J(\C[G])$ es un ideal, 
% 	\[
% 		\alpha=\frac{\beta^*\beta}{\trace(\beta^*\beta)}\in J(\C[G]).
% 	\]
% 	Este elemento $\alpha$ cumple que $\alpha^*=\alpha$ y $\trace(\alpha)=1$.
% 	Luego $\trace(\alpha^{2^m})\geq 1$ para todo $m\geq1$.
% \end{proof}

% El ejercicio~\ref{exa:norma} implica que $\C[G]$ con
% $\dist(\alpha,\beta)=|\alpha-\beta|$ es un espacio métrico. En este espacio
% métrico, la función $\C[G]\to\C$, $\alpha\mapsto \trace(\alpha)$, es una
% función continua.

% \begin{lemma}
% 	\label{lem:phi_diferenciable}
% 	Sea $\alpha\in J(\C[G])$. La función
% 	\[
% 		\varphi\colon\C\to\C[G],\quad
% 		\varphi(z)=(1-z\alpha)^{-1},
% 	\]
% 	es continua, diferenciable y $\varphi(z)=\sum_{n\geq0}\alpha^nz^n\in\C[G]$ si $|z|$
% 	es suficientemente pequeño.
% \end{lemma}

% \begin{proof}	
% 	Sean $y,z\in\C$. Como $\varphi(y)$ y $\varphi(z)$ conmutan, 
% 	\begin{equation}
% 		\label{eq:Rickart}
% 		\begin{aligned}
% 			\varphi(y)-\varphi(z)&=\left( (1-z\alpha)-(1-y\alpha)\right)(1-y\alpha)^{-1}(1-z\alpha)^{-1}\\
% 			&=(y-z)\alpha\varphi(y)\varphi(z).
% 		\end{aligned}
% 	\end{equation}
% 	Entonces $|\varphi(y)|\leq|\varphi(z)|+|y-z||\alpha\varphi(y)||\varphi(z)|$ y luego
% 	\[
% 		|\varphi(y)|\left( 1-|y-z||\alpha\varphi(z)|\right)\leq|\varphi(z)|.
% 	\]
% 	Fijado $z$ podemos elegir $y$ suficientemente cerca de $z$ de forma tal que
% 	se cumpla que  $1-|y-z||\alpha\varphi(z)|\geq1/2$. Luego
% 	$|\varphi(y)|\leq2|\varphi(z)|$. De la igualdad~\eqref{eq:Rickart} se
% 	obtiene entonces $|\varphi(y)-\varphi(z)|\leq2|y-z||\alpha||\varphi(z)|^2$
% 	y luego $\varphi$ es una función continua. Por la
% 	expresión~\eqref{eq:Rickart}, 
% 	\[
% 	\varphi'(z)
% 	=\lim_{y\to z}\frac{\varphi(y)-\varphi(z)}{y-z}
% 	=\lim_{y\to z}\alpha\varphi(y)\varphi(z)
% 	=\alpha\varphi(z)^2
% 	\]
% 	para todo $z\in\C$.

% 	Si $z$ es tal que $|z||\alpha|=|z\alpha|<1$, entonces 
% 	\[
% 		\varphi(z)-\sum_{n=0}^Nz^n\alpha^n
% 		=\varphi(z)\left(1-(1-z\alpha)\sum_{n=0}^Nz^n\alpha^n\right)
% 		=\varphi(z)(z\alpha)^{N+1}
% 	\]
% 	y luego
% 	\[
% 		\left|\varphi(z)-\sum_{n=0}^Nz^n\alpha^n\right|\leq|\varphi(z)||z\alpha|^{N+1}.
% 	\]
% 	Como $\varphi(z)$ está acotada cerca de $z=0$, se concluye que
% 	$\left|\varphi(z)-\sum_{n=0}^Nz^n\alpha^n\right|\to0$ si $N\to\infty$.
% \end{proof}

% Estamos en condiciones de demostrar el teorema de Rickart:

% \begin{theorem}[Rickart]
% 	\index{Teorema!de Rickart}
% 	Si $G$ es un grupo, entonces $J(\C[G])=0$.
% \end{theorem}

% \begin{proof}
% 	Sea $\alpha\in J(\C[G])$ y sea $\varphi(z)=(1-\alpha z)^{-1}$. Sea 
% 	$f\colon\C\to \C$ dada por
% 	$f(z)=\trace\varphi(z)=\trace\left((1-z\alpha)^{-1}\right)$. Por el lema~\ref{lem:phi_diferenciable},
% 	$f(z)$ es una función entera tal que $f'(z)=\trace(\alpha\varphi(z)^2)$ y
% 	\begin{equation}
% 		\label{eq:Taylor}
% 		f(z)=\sum_{n=0}^\infty z^n\trace(\alpha^n)
% 	\end{equation}
% 	si $|z|$ es suficientemente pequeño. En particular, la
% 	igualdad~\eqref{eq:Taylor} es la expansión en serie de Taylor para $f(z)$
% 	en el origen. Esto implica que esta serie tiene radio de convergencia
% 	infinito y converge a $f(z)$ para todo $z\in\C$. En particular,
% 	\begin{equation}
% 		\label{eq:limite}
% 		\lim_{n\to\infty}\trace(\alpha^n)=0.
% 	\end{equation}
% 	Por otro lado, si $\alpha\ne0$ el lema~\ref{lem:algebraico} implica que
% 	$\trace(\alpha^{2^m})\geq1$ para todo $m\geq0$, lo que contradice el límite
% 	calculado en~\eqref{eq:limite}. Luego $\alpha=0$.
% \end{proof}

% Para demostrar un corolario necesitamos dos lemas:

% \begin{lemma}[Nakayama]
% 	\label{lem:Nakayama}
% 	\index{Lema!de Nakayama}
% 	Sea $R$ un anillo unitario y sea $M$ un $R$-módulo finitamente generado. Si
% 	$J(R)M=M$, entonces $M=0$.
% \end{lemma}

% \begin{proof}
% 	Supongamos que $M$ está generado por los elementos $x_1,\dots,x_n$. Como $x_n\in M=J(R)M$, 
% 	existen $r_1,\dots,r_n\in J(R)$ tales que $x_n=r_1x_1+\cdots+r_nx_n$, es decir
% 	$(1-r_n)x_n=\sum_{j=1}^{n-1}r_jx_j$. 
% 	Como $1-r_n$ es inversible, existe $s\in R$ tal que $s(1-r_n)=1$. Luego
% 	$x_n=\sum_{j=1}^{n-1}sr_jx_j$ 
% 	y entonces $M$ está generado por $x_1,\dots,x_{n-1}$. Al repetir este
% 	procedimiento una cierta cantidad finita de veces, se obtiene que $M=0$.
% \end{proof}

% \begin{lemma}
% 	\label{lem:Rickart}
% 	Sea $\iota\colon R\to S$ un morfismo de anillos unitarios. Si 
% 	\[
% 	S=\iota(R)x_1+\cdots+\iota(R)x_n,
% 	\]
% 	donde cada $x_j$ cumple que $x_jy=yx_j$ para todo $y\in\iota(R)$, entonces
% 	$\iota(J(R))\subseteq J(S)$.
% \end{lemma}

% \begin{proof}
% 	Veamos que $J=\iota(J(R))$ actúa trivialmente en cada $S$-módulo simple $M$.
% 	Si $M$ es un $S$-módulo simple, escribimos $M=Sm$ para algún $m\ne0$. Es
% 	claro que $M$ es un $R$-módulo con $r\cdot m=\iota(r)m$. Como
% 	\[
% 		M=Sm=(\iota(R)x_1+\cdots+\iota(R)x_n)m=\iota(R)(x_1m)+\cdots+\iota(R)(x_nm),
% 	\]
% 	$M$ es finitamente generado como $\iota(R)$-módulo. Además $J(R)\cdot
% 	M=JM=\iota(J)M$ es un $S$-submódulo de $M$ pues
% 	\[
% 		x_j(JM)=(x_jJ)M=(Jx_j)M=J(x_jM)\subseteq JM.
% 	\]
% 	Como $M\ne0$, el lema de Nakayama implica que $J(R)\cdot M\subsetneq M$. Luego,
% 	como $M$ es un $S$-módulo simple, se concluye que $J(R)M=0$.
% \end{proof}

% \begin{corollary}
% 	Si $G$ es un grupo, entonces $J(\R[G])=0$. 
% \end{corollary}

% \begin{proof}
% 	Sea $\iota\colon \R[G]\to\C[G]$ la inclusión canónica. Como 
% 	\[
% 	\C[G]=\R[G]+i\R[G],
% 	\]
% 	el lema~\ref{lem:Rickart} y el teorema de Rickart implican que
% 	$\iota(J(\R[G]))\subseteq J(\C[G])=0$. Luego $J(\R[G])=0$ pues $\iota$ es
% 	inyectiva. 
% \end{proof}


\topic{Anillos semiprimitivos y semiprimos}

\begin{definition}
	\index{Anillo!semiprimitivo}
	\index{Anillo!semisimple Jacobson}
	Un anillo $R$ se dice \textbf{semiprimitivo} (o semisimple Jacobson) si
	$J(R)=0$.
\end{definition}

\begin{example}
	Si $R$ es primitivo entonces es semiprimitivo. En efecto, como $R$ es
	primitivo, $\{0\}$ es un ideal primitivo y luego, como $J(R)$ es la
	intersección de los ideales primitivos de $R$, se concluye que $J(R)=0$.
\end{example}

\begin{example}
	Si $R=\prod_{i\in I}R_i$ es producto directo de anillos semiprimitivos,
	entonces $R$ es semiprimitivo pues 
	\[
		J(R)=J\left(\prod_{i\in I}R_i\right)=J\left(\prod_{i\in I}J(R_i)\right)=0.
	\]
\end{example}

\begin{example}
	$\Z$ es semiprimitivo pues $J(\Z)=\cap_{p}\Z/p=\{0\}$.
\end{example}

\begin{example}
	Sea $R=C[a,b]$ el anillo de funciones $f\colon [a,b]\to\R$ continuas. Como
	$R$ es un anillo unitario, $J(R)$ es la intersección de los ideales
	maximales de $R$. Todo ideal maximal de $R$ es de la forma
	\[
		U_c=\{f\in C[a,b]:f(c)=0\}
	\]
	para algún $c\in[a,b]$. En efecto, es fácil ver que cada $U_c$ es un ideal;
	$U_c$ es maximal pues $C[a,b]/U_c\simeq\R$.  Luego $J(R)=\cap_{a\leq c\leq
	b}U_c=0$.
\end{example}

\begin{theorem}
	\label{thm:semiprimitivo}
	Si $R$ es un anillo, entonces $R/J(R)$ es semiprimitivo. 
\end{theorem}

\begin{proof}
	Si $R$ es un anillo radical, el resultado es trivial. Supongamos entonces
	que $J(R)\ne R$ y sea $M$ un módulo simple. Entonces $M$ es un
	$R/J(R)$-módulo simple con
	\[
		(x+J(R))m=xm,\quad
		x\in R,\,m\in M.
	\]
	Si $x+J(R)\in J(R/J(R))$ entonces $xM=(x+J(R))M=0$. Luego $x\in J(R)$ pues
	$x$ anula a cualquier módulo simple de $R$.
\end{proof}

%El teorema de densidad de Jacobson nos permite entonces obtener el siguiente resultado:
%
%\begin{theorem}
%	Sea $R$ un anillo no radical. Entonces $R/J(R)$ es isomorfo a un producto
%	subdirecto de anillos densos en espacios vectoriales sobre anillos de
%	división.	
%\end{theorem}
%
%\begin{proof}
%	Si $R$ no es radical, $J(R)\ne R$. Luego $R/J(R))$ es semiprimitivo por el
%	teorema~\ref{thm:semiprimitivo}. El teorema~\ref{thm:subdirecto} y el
%	teorema de densidad de Jacobson completan la demostración del teorema.
%\end{proof}


\begin{definition}
	\index{Producto subdirecto de anillos}
	Sea $\{R_i:i\in I\}$ una familia de anillos. Un subanillo $R$ de
	$\prod_{i\in I}R_i$ se dice un \textbf{producto subdirecto} de los $R_j$ si
	cada $\pi_j\colon R\to R_j$ es sobreyectiva. 
\end{definition}

El siguiente teorema justifica que indistintamente llamemos anillos
semiprimitivos a los anillos semisimples Jacobson:

\begin{theorem}
	\label{thm:subdirecto}
	Sea $R$ un anillo no nulo. Entonces $R$ semiprimitivo si y sólo si $R$ es
	isomorfo a un producto subdirecto de anillos primitivos.
\end{theorem}

\begin{proof}
	Supongamos que $R$ es semiprimitivo y sea $\{P_i:i\in I\}$ la familia de
	ideales primitivos de $R$. Cada $R/P_j$ es primitivo y
	$\{0\}=J(R)=\cap_{i\in I}P_i$. Para cada $j$, sean $\lambda_j\colon R\to
	R/P_j$ y $\pi_j\colon \prod_{i\in I}R/P_i\to R/P_j$ los morfismos
	canónicos. La función
	\[
		\phi\colon R\to\prod_{i\in I}R/P_i,\quad
		r\mapsto \{\lambda_i(r):i\in I\},
	\]
	es un morfismo inyectivo de anillos tal que $\pi_j\phi(R)=R/P_j$ para todo
	$j$.

	Supongamos ahora que $R$ es isomorfo a un producto subrirecto de anillos
	$R_j$ primitivos y sea $\varphi\colon R\to\prod_{i\in I}R_i$ un morfismo
	inyectivo tal que $\pi_j(\varphi(R))=R_j$ para todo $j$. Para cada $j$ sea
	$P_j=\ker\pi_j\varphi$. Como $R/P_j\simeq R_j$, cada $P_j$ es un ideal
	primitivo. Si $x\in\cap_{i\in I}P_i$ entonces $\varphi(x)=0$ y luego $x=0$.
	Luego $J(R)\subseteq\cap_{i\in I} P_i=0$. 
\end{proof}

\begin{example}
	El anillo $\Z$ es isomorfo a un producto subdirecto de los cuerpos $\Z/p$
	con $p$ primo.
\end{example}

\begin{example}
	El anillo $C[a,b]$ es isomorfo a un producto subdirecto de los cuerpos
	$C[a,b]/U_c\simeq\R$.
\end{example}

\begin{definition}
	Un anillo $R$ se dice \textbf{semiprimo} si para todo $a\in R$ tal que
	$aRa=0$ se tiene que $a=0$.
\end{definition}

\begin{lemma}
	Sea $R$ un anillo. Son equivalentes:
	\begin{enumerate}
		\item $R$ es semiprimo.
		\item Si $I$ es un ideal a izquierda tal que $I^2=0$ entonces $I=0$.
		\item Si $I$ es un ideal tal que $I^2=0$ entonces $I=0$.
		\item $R$ no tiene ideales nilpotentes no nulos. 
	\end{enumerate}
\end{lemma}

\begin{proof}
	Veamos que $(1)\implies(2)$. Si $I^2=0$ y $x\in I$, entonces $xRx\subseteq I^2=0$ y
	luego $x=0$. Las implicaciones $(2)\implies(3)$ y $(4)\implies(3)$ son triviales. Veamos que
	$(3)\implies(4)$.  Si $I$ es un ideal nilpotente no nulo, sea $n\in\Z_{>0}$ 
	minimal tal que $I^n=0$.  Como $(I^{n-1})^2=0$, $I^{n-1}=0$, una
	contradicción. Por último veamos que $(3)\implies(1)$. Sea $a\in R$ tal que
	$aRa=0$. Entonces $I=RaR$ es un ideal de $R$ tal que $I^2=0$. Por hipótesis, $RaR=I=0$. Luego
	$Ra$ y $aR$ son ideales tales que $(Ra)R=R(aR)=0$. Esto implica que $\Z a$ es un ideal de $R$
	tal que $(\Z a)R=0$ y luego $a=0$.
\end{proof}

\begin{example}
	Un anillo conmutativo es semiprimo si y sólo si no tiene elementos
	nilpotentes no nulos.
\end{example}


\begin{proposition}
	El anillo $\C[G]$ es semiprimo.
\end{proposition}

\begin{proof}
	Como $J(\C[G])=0$ por el teorema de Rickart y además el radical de Jacboson
	contiene a todo ideal nil por la proposición~\ref{pro:nilJ}, se deduce que
	$\C[G]$ no tiene ideales nil no triviales. Tampoco tiene entonces ideales
	nilpotentes no triviales y luego $\C[G]$ es semiprimo.
\end{proof}

\begin{exercise}
	Demuestre que $Z(\C[G])$ es semiprimo.
\end{exercise}

% tomar $\alpha$ tal que $\alpha^2=0$ y sea $A=K[G]\alpha$. Como $A^2=0$, $A=0$ y entonces $\alpha=0$.

\begin{example}
	Sea $D$ un anillo de división. Entonces $D[X]$ es semiprimo.
\end{example}

\begin{example}
	Sea $D$ un anillo de división. Entonces $D[[X]]$ es semiprimo y no es
	semiprimitivo.
\end{example}




%\section{Anillos semiprimitivos}
%
%\begin{lemma}
%	\label{lem:Iunitario}
%	Sea $R$ un anillo y sea $I$ un ideal de $R$ unitario. Sea $e\in I$ la
%	unidad de $I$. Entonces $e$ es un idempotente central de $R$, $I=eR$ y
%	existe un ideal $J$ de $R$ tal que $R=I\oplus J$. Además $R\simeq I\times
%	J$.
%\end{lemma}
%
%\begin{proof}
%	Como $e\in I$, $eR\subseteq I$. Luego $I=eR$ pues $I=eI\subseteq eR$. Como
%	$ex\in I$ y $xe\in I$ para todo $x\in R$, $ex=(ex)e$ y $xe=e(xe)$. Luego
%	$ex=xe$ y entonces $e$ es central e idempotente. Sea $J=\{x-ex:x\in R\}$.
%	Es fácil demostrar que $J$ es un ideal tal que $R=I\oplus J$. Además
%	$R\simeq I\times J$, via $x\mapsto (ex,x-ex)$,
%\end{proof}
%
%A continuación daremos una demostración muy sencilla del teorema de Wedderburn
%en el caso de álgebras de dimensión finita.
%
%\begin{theorem}[Artin--Wedderburn]
%	Sea $R$ un anillo artiniano a izquierda y no nulo. Entonces $R$ es
%	semiprimo si y sólo si existen $n_1,\dots,n_r\in\N$ y existen anillos de
%	división $D_1,\dots,D_r$ tales que $R\simeq M_{n_1}(D_1)\times\cdots\times
%	M_{n_r}(D_r)$.
%\end{theorem}
%
%\begin{proof}
%	Procederemos por inducción en $\dim A$. Si $\dim A=1$\dots\framebox{} 
%
%	Supongamos entonces que $\dim A>1$. Si $A$ es un álgebra prima, el
%	resultado se sigue inmediatamente del teorema de Wedderburn. Supongamos
%	entonces que existe $a\in A\setminus\{0\}$ tal que $I=\{x\in A:aAx=0\}$ es
%	no nulo. Como $I$ es un ideal de $A$, $I$ es un álgebra semiprima.
%	\framebox{?} Como $a\not\in I$, $\dim I<\dim A$, y entonces, por hipótesis
%	inductiva, existen $n_1,\dots,n_s\in\N$ y álgebras de división
%	$D_1,\dots,D_s$ tales que 
%	\[
%		I\simeq M_{n_1}(D_1)\times\cdots\times M_{n_s}(D_s).
%	\]
%	En particular, $I$ es unitario. Por el lema~\ref{lem:Iunitario}, existe un
%	ideal $J$ de $A$ tal que $A\simeq I\times J$. Como $\dim J<\dim A$, la hipótesis inductiva
%	implica que existen $n_{s+1},\dots,n_r\in\N$ y álgebras de división $D_{s+1},\dots,D_r$ tales que
%	\[
%		J\simeq M_{n_{s+1}}(D_{s+1})\times\cdots\times M_{n_r}(D_r).
%	\]
%	Luego $A\simeq I\times J\simeq \prod_{j=1}^s M_{n_j}(D_j)$.
%\end{proof}
%
%\begin{corollary}
%	Sea $A$ un álgebra no nula de dimensión finita. Si $A$ es semiprima,
%	entonces $A$ es unitaria.
%\end{corollary}
%
%%Gracias al teorema de Wedderburn se puede ir un poco más lejos:
%%\begin{corollary}
%%	Sea $A$ un álgebra unitaria. Son equivalentes:
%%	\begin{enumerate}
%%		\item $A$ es semiprima.
%%		\item Todo $A$-módulo unitario es semisimple.
%%		\item $A$ es semisimple como $A$-módulo.
%%		\item Todo ideal a izquierda de $A$ es de la forma $Ae$ para algún
%%			idempotente $e\in A$. 
%%	\end{enumerate}
%%\end{corollary}
%%
%%\begin{proof}
%%	La implicación $(1)\implies(2)$ es el teorema de Wedderburn. 
%%	
%%\end{proof}
%
%\begin{example}
%	Por el teorema de Maschke sabemos que si $G$ es un grupo finito, 
%	$\C[G]$ es un álgebra semiprimitiva y luego semisimple.
%\end{example}
%




%\section{Viejo!}
%
%\begin{theorem}[Artin--Wedderburn]
%	\index{Teorema!de Artin--Wedderburn}
%	\label{thm:ArtinWedderburn}
%	Si $R$ es un anillo, las siguientes afirmaciones son equivalentes:
%	\begin{enumerate}
%		\item $R$ es un anillo no nulo semiprimitivo y artiniano a izquierda.
%		\item Existen anillos de división $D_1,\dots,D_r$ y tales que
%			\[
%				R\simeq\prod_{i=1}^r R_i,
%			\]
%			donde $R_i=\End_{D_i}(V_i)$
%		\item Existen anillos de división $D_1,\dots,D_r$ y enteros positivos
%			$n_1,\dots,n_r$ tales que 
%			\[
%			R\simeq M_{n_1}(D_1)\times\cdots\times M_{n_r}(D_r).
%		\]
%	\end{enumerate}
%\end{theorem}
%
%\begin{proof}
%	Demostremos que $(1)\implies(2)$. Como $R\ne0$ y $J(R)=0$, $R$ admite
%	ideales primitivos. Supongamos que existe un número finito de ideales
%	primitivos distintos, digamos $P_1,\dots,P_t$. Cada $R/P_j$ es un anillo
%	primitivo y es artiniano a izquierda \framebox{?}. Entonces, por el teorema
%	de Wedderburn, para cada $j\in\{1,\dots,t\}$ existen un anillo de división
%	$D_j$ y un entero positivo $n_j$ tales que $R/P_j\simeq M_{n_j}(D_j)$. En
%	particular, cada $R/P_j$ es simple y entonces $P_j$ es un ideal maximal de
%	$R$. Como $R/P_j$ es simple, $(R/P_j)^2\ne 0$ y luego $R^2\not\subseteq
%	P_j$. Por maximalidad, $R^2+P_j=R$ y además $P_i+P_j=R$ para todo $i\ne j$.
%	Por el teorema chino del resto,
%	\[
%		R=R/0=R/J(R)=R/\cap_{j=1}^t P_j\simeq R/P_1\times\cdots\times R/P_t.
%	\]
%	Sea $\iota_k\colon R/P_k\to \prod_{j=1}^t R/P_j$ la inclusión canónica.
%	Cada $\iota_k(R/P_k)$ es un ideal simple (es decir, que como anillo es
%	simple) de $\prod_{j=1}^t R/P_j\simeq R$. Luego las imágenes, digamos
%	$I_k$, de los $\iota_k(R/P_k)$ dan ideales simples de $R$ y
%	$R=I_1\times\cdots\times I_t$.
%
%	Demostremos ahora que $(3)\implies(1)$. Para cada $j$ sea
%	$R_j=M_{n_j}(D_j)$. Como cada $R_j$ es primitivo por el teorema de
%	Wedderburn, $J(R_j)=\{0\}$ para todo $j$. Luego
%	$J(R)=\prod_{i=1}^rJ(R_j)=\{0\}$ y entonces $R$ es semiprimitivo. Además
%	$R$ es artiniano a izquierda.\framebox{?}
%\end{proof}
%
%\begin{corollary}
%	Sea $R$ un anillo semiprimitivo.
%	\begin{enumerate}
%		\item Si $R$ es artiniano a izquierda, entonces $R$ es unitario.
%		\item $R$ es artiniano a izquierda si y sólo si es artiniano a derecha.
%		\item Si $R$ es artiniano a izquierda es noetheriano.
%	\end{enumerate}
%\end{corollary}
%
%\begin{proof}
%	La primera afirmación es consecuencia inmediata del teorema de
%	Artin--Wedderburn~\ref{thm:ArtinWedderburn}.
%\end{proof}
%
%\begin{corollary}
%	Sea $R$ un anillo semiprimitivo artiniano a izquierda y sea $I$ un ideal de
%	$R$. Entonces $I=Re$ para algún idempotente $e\in R$ tal que $e\in Z(R)$.
%\end{corollary}
%
%\begin{proof}
%		
%\end{proof}
%
%\begin{proposition}
%	Sea $R$ un anillo semisimple artiniano a izquierda. 
%	\begin{enumerate}
%		\item $R=I_1\times\cdots\times I_n$ donde los $I_j$ son ideales simples.
%		\item Si $J\subseteq R$ es un ideal simple, entonces existe $k\in\{1,\dots,n\}$ tal que $J=I_k$.
%		\item Si $R=J_1\times\cdots\times J_m$ donde los $J_k$ son ideales simples, entonces $n=m$ y existe
%			$\sigma\in\Sym_n$ tal que $I_k=J_{\sigma(k)}$ para todo $k\in\{1,\dots,n\}$.
%	\end{enumerate}
%\end{proposition}
%
%\begin{proof}
%\end{proof}
%
%\begin{theorem}
%	Sea $R$ un anillo unitario no nulo. Las siguientes afirmaciones son
%	equivalentes:
%	\begin{enumerate}
%		\item $R$ es semiprimitivo y artiniano a izquierda.
%		\item Todo $R$-módulo unitario es proyectivo.
%		\item Todo $R$-módulo unitario es inyectivo.
%		\item Toda sucesión exacta de $R$-módulos unitarios se parte.
%		\item Todo $R$-módulo unitario no nulo es semisimple.
%		\item $\prescript{}{R}R$ es unitario y semisimple.
%		\item Todo ideal a izquierda de $R$ es de la forma $Re$ para algún $e\in R$ indempotente.
%		\item $\prescript{}{R}R$ es suma directa de ideales a izquierda
%			minimales $L_1,\dots,L_m$ donde cada $L_j$ es de la forma $Re_j$, y
%			los $e_j$ son idempotentes ortogonales tales que
%			$e_1+\cdots+e_m=1$. 
%	\end{enumerate}
%\end{theorem}
%
%\begin{proof}
%	Veamos que $(4)\implies(5)$. Sea $M$ un módulo unitario y sea $N$ un
%	submódulo no nulo de $M$. Como la sucesión $0\to N\to M\to M/N\to 0$ es
%	exacta, se parte. Luego $M=N\oplus X$ para algún submódulo $X$ de $N$ tal
%	que $X\simeq M/N$. Como $M$ es unitario, $Rm\ne 0$ para todo $m\in
%	M\setminus\{0\}$. Luego $M$ es semisimple por el teorema~\framebox{?}.
%
%	Veamos ahora que $(5)\implies(4)$. Sea 
%	\[
%	\begin{tikzcd}
%		0 \arrow[r]
%		& N \arrow[r]
%		& M \arrow[r]
%		& X \arrow[r]
%		& 0
%	\end{tikzcd}
%	\]
%	una sucesión exacta corta de $R$-módulos. Como $f\colon N\to f(N)$ es un
%	isomorfismo y entonces $f(N)$ es un submódulo del semisimple $M$, $f(N)$ es
%	sumando directo de $M$. Sea $\pi\colon M\to f(N)$ el morfismo canónico.
%	Entonces $\pi f=f$ y $f^{-1}\pi\colon M\to A$ es un morfismo tal que
%	$(f^{-1}\pi)f=\id_N$.\framebox{?}
%
%	Demostremos que $(5)\implies(7)$. Sea $L$ un ideal a izquierda de $R$. Como
%	los ideales a izquierda de $R$ son los submódulos de $\prescript{}{R}R$,
%	existe un ideal a izquierda $N$ de $R$ tal que $R=L\oplus N$. Existen
%	entonces $e_1\in L$ y $e_2\in N$ tales que $1=e_1+e_2$. Si $x\in L$,
%	entonces $x=xe_1+xe_2$ y luego $xe_2=x-xe_1\in L\cap N=\{0\}$. Demostramos
%	entonces que $x=xe_1$ para todo $x\in L$. En particular, $e_1e_1=e_1$ y
%	$L=Re_1$. 
%
%	Demostremos que $(7)\implies(6)$. Sea $L$ un submódulo de
%	$\prescript{}{R}R$. Como entonces $L$ es un ideal a izquierda de $R$,
%	$L=Re$ para algún idempotente $e\in R$. Como el conjunto $R(1-e)$ es un
%	ideal a izquierda de $R$ tal que $R=Re\oplus R(1-e)$, se concluye que
%	$\prescript{}{R}R$ es semisimple.\framebox{?}
%
%	Veamos que $(6)\implies(1)$. Supongamos que $\prescript{}{R}R=\sum_{i\in
%	I}N_i$, donde los $N_j$ son submódulos simples de $\prescript{}{R}R$.
%	Reordenando los $N_j$ si fuera necesario, podemos suponer que existe
%	$k\in\N$ tal que $1=e_1+\cdots+e_k$ y $e_j\in N_j$ para todo
%	$j\in\{1,\dots,k\}$. Si $r\in R$, entonces $r=re_1+\cdots+re_k\in
%	\sum_{i=1}^k N_i$. Luego $R=\sum_{i=1}^k N_i$.
%	Veamos que $J(R)=0$. Si $r\in J(R)$ entonces, como $rN_i=0$ para todo
%	$i\in\{1,\dots,k\}$, se concluye que $r=r1=re_1+\cdots+re_k=0$. Probamos
%	entonces que $R$ es semiprimitivo. Falta ver que $R$ es artiniano a
%	izquierda. Para eso basta obvervar que, como
%	\[
%		\frac{N_1\oplus\cdots\oplus N_i}{N_1\oplus\cdots\oplus N_{i-1}}\simeq N_i
%	\]
%	para cada $i\in\{1,\dots,k\}$, la serie
%	\[
%	R=N_1\oplus\cdots\oplus N_k\supsetneq N_1\oplus\cdots\oplus N_{k-1}\supsetneq\cdots\supsetneq N_1\oplus N_2\supsetneq N_1\supsetneq 0
%	\]
%	es una serie de composición.\framebox{?}
%
%	Veamos que $(1)\implies(8)$. Sin perder generalidad podemos suponer que
%	\[
%	R=\prod_{i=1}^k M_{n_j}(D_j),
%	\]
%	donde los $D_j$ son anillos de división.\framebox{?}
%
%	Veamos que $(8)\implies(5)$. Sea $M$ un módulo unitario no nulo. Si $m\in
%	M$ entonces $L_im$ es un submódulo de $M$. Los $L_jm$ generan a $M$ pues 
%	\[
%	m=1m=e_1m+\cdots+e_km\in\sum L_im.
%	\]
%	Veamos que cada $L_jm$ es simple. Fijado $i$, la función $f\colon L_i\to
%	L_im$, $x\mapsto xm$, es un morfismo sobreyectivo. Como $L_i$ es un ideal a
%	izquierda minimal, $L_i$ es un submódulo simple. Luego $m\ne0$ implica que
%	$f$ es un isomorfismo. Probamos entonces que el conjunto $\{L_jm:1\leq
%	j\leq k,m\in M,L_jm\ne 0\}$ es una familia de submódulos simples cuya suma
%	es $M$.
%\end{proof}


\topic{Jacobson's density theorem}

\begin{definition}
	\index{Anillo!denso de operadores lineales}
	Sean $D$ un anillo de división y $V$ un espacio vectorial sobre $D$. Un
	subanillo $R\subseteq\End_D(V)$ se dice \textbf{denso} en $V$ si para cada
	$n\in\Z_{>0}$, cada $\{u_1,\dots,u_n\}\subseteq V$ linealmente independiente de
	$V$ y cada conjunto $\{v_1,\dots,v_n\}\subseteq V$ (no necesariamente
	linealmente independiente) existe $f\in R$ tal que $f(u_j)=v_j$ para todo
	$j\in\{1,\dots,n\}$.
\end{definition}

%\begin{lemma}
%	Sea $R$ un subanillo de $\End_D(V)$. Entonces $R$ es denso en $V$ si y sólo
%	si para todo $g\in\End_D(V)$ y todo subespacio $U$ de $V$ de dimensión
%	finita existe $f\in R$ tal que $f|_U=g|_U$.
%\end{lemma}
%
%\begin{proof}
%	Supngamos que $R$ es denso en $V$. Sean $g\in\End_D(V)$ y $U\subseteq V$ un
%	subespacio de dimensión finita. Sea $\{u_1,\dots,u_n\}$ una base de $U$.
%	Como $R$ es denso, existe $f\in R$ tal que $f(u_j)=g(u_j)$ para todo
%	$j\in\{1,\dots,n\}$ y luego $f|_U=g|_U$.
%
%	Recíprocamente, sea $n\in\N$ y sean $\{u_1,\dots,u_n\}\subseteq V$ un
%	conjunto linealmente independiente y $\{v_1,\dots,v_n\}\subseteq V$. Sean
%	$g\in\End_D(V)$ tal que $g(u_j)=v_j$ para todo $j\in\{1,\dots,n\}$ y $U$ el
%	subespacio de $V$ generado por $u_1,\dots,u_n$. Por hipótesis existe $f\in
%	R$ tal que $f|_U=g|_U$ y luego $f(u_j)=g(u_j)=v_j$ para todo
%	$j\in\{1,\dots,n\}$.
%\end{proof}

\begin{lemma}
	\label{lem:unico_denso}
	Sea $D$ un anillo de división 
	$V$ un $D$-espacio vectorial de dimensión finita. Entonces $\End_D(V)$ es
	el único anillo denso en $V$.
\end{lemma}

\begin{proof}
	Sea $R$ denso en $V$ y sea $\{v_1,\dots,v_n\}$ una base de $V$. Por
	definición, $R\subseteq\End_D(V)$. Si $g\in\End_D(V)$ entonces, como $R$ es
	denso en $V$, existe $f\in R$ tal que $f(v_j)=g(v_j)$ para todo
	$j\in\{1,\dots,n\}$. Luego $g=f\in R$.
\end{proof}

\begin{lemma}
	\label{lem:ideal_denso}
	Sea $R$ un anillo denso en $V$ y sea $I$ un ideal no nulo de $R$. Entonces
	$I$ es denso en $V$.
\end{lemma}

\begin{proof}
	Sea $I$ un ideal no nulo de $R$. Sean $h\in I\setminus\{0\}$ y $u\in V$
	tales que $h(u)=v\ne0$. Sea $\{u_1,\dots,u_n\}\subseteq V$ un conjunto
	linealmente independiente y sea $\{v_1,\dots,v_n\}\subseteq V$. Como $R$ es
	denso en $V$, existen $g_1,\dots,g_n\in R$ tales que $g_i(u_i)=u$ y
	$g_i(u_j)=0$ si $i\ne j$. Existen además $f_1,\dots,f_n\in R$ tales que
	$f_i(v)=v_i$. Entonces $\gamma=\sum_{i=1}^n f_ihg_i\in I$ cumple que
	$\gamma(u_j)=v_j$ para todo $j\in\{1,\dots,n\}$.
\end{proof}

%Ahora demostraremos el teorema de densidad de Jacobson. 
%Necesitaremos el siguiente
%lema:
%\begin{lemma}
%	\label{lem:densidad}
%	Sea $M$ un $R$-módulo simple y $D=\End_R(M)$.  Si $N$ es un subespacio de
%	$M$ tal que $\dim_DN<\infty$ y $m\in M\setminus N$, entonces existe $r\in
%	R$ tal que $rm\ne 0$ y $rN=0$.
%\end{lemma}
%
%\begin{proof}
%	Supongamos que la afirmación no es cierta y sea $N$ un contraejemplo de la
%	mínima dimensión posible. Entonces $\dim_DN\geq1$ (pues el resultado es
%	verdadero en el caso $N=0$). Sea $N_0$ un subespacio de $N$ tal que $\dim
%	N_0=\dim N-1$ y sea
%	\[
%		L=\{r\in R:rN_0=0\}.
%	\]
%	Como por la minimalidad de $N$ nuestra afirmación es cierta para $N_0$,
%	para cualquier $x\in N\setminus N_0$ se tiene que $Lx=N$ (pues existe $r\in
%	L$ tal que $rx=\ne 0$). Como $L$ es ideal a izquierda de $R$ y
%	$Lx\subseteq N$ es un submódulo, $Lx=N$ pues $N$ es simple.
%
%	Sea $w\in V\setminus U$ tal que nuestra afirmación no es cierta y sea $u\in
%	U\setminus U_0$.  La función 
%	\[
%		\delta\colon V\to V,\quad
%		v\mapsto lw,
%	\]
%	donde $v=lu\in Lu=V$ (que depende de $u$ y $w$) 
%	está bien definida: si $l_1,l_2\in L$ son tales que $v=l_1u=l_2u$ entonces $(l_1-l_2)u=0$ y luego
%	\[
%		0=\delta(0)=\delta((l_1-l_2)u)=(l_1-l_2)w=l_1w-l_2w. 
%	\]
%	Además $\delta$ es morfismo de $R$-módulos pues si $l\in L$ es tal que $v=lu$ entonces
%	\[
%		\delta(rv)=\delta(r(lu))=\delta( (rl)u)=(rl)w=r(lw)=r\delta(v)
%	\]
%	para todo $r\in R$.
%
%
%\end{proof}

\begin{theorem}[densidad de Jacobson]
	\label{thm:densidad}
	\index{Teorema!de densidad de Jacobson}
	\index{Jacobson!densidad de}
	Un anillo $R$ es primitivo si y sólo si es isomorfo a un anillo denso en un
	espacio vectorial sobre un anillo de división.
\end{theorem}

\begin{proof}
	Si $R$ es isomorfo a un anillo
	denso en un $D$-módulo $V$ donde $D$ es un anillo de división, entonces $R$
	es primitivo pues $V$ es un módulo simple y fiel. Es fiel: si
	$f\in\Ann_R(V)$ entonces $f=0$ pues $f(v)=0$ para todo $v\in V$. Es simple
	pues si $W\subseteq V$ es un submódulo no nulo, $v\in V$ y $w\in
	W\setminus\{0\}$ entonces existe $f\in R$ tal que $v=f(w)\in W$. 

	Supongamos ahora que $R$ es primitivo y sea $V$ un módulo simple y fiel.
	Por el lema de Schur, $D=\End_R(V)$ es un anillo de división. Luego $V$ es
	un $D$-espacio vectorial con las operaciones
	\[
	\delta v=\delta(v),\quad
	\delta(rv)=r(\delta v),\quad
	v\in V,r\in R,\delta\in D.
	\]
	Para $r\in R$ definimos 
	\[
		\gamma_r\colon V\to V,\quad
		v\mapsto rv.
	\]
	Es fácil ver que $\gamma_r\in\End_D(V)$ y que la función $R\to\End_D(V)$,
	$r\mapsto\gamma_r$, es un morfismo de anillos. Como $V$ es fiel,
	$R\simeq\gamma(R)=\{\gamma_r:r\in R\}$ (si $\gamma_r=\gamma_s$ entonces
	$rv=\gamma_r(v)=\gamma_s(v)=sv$ para todo $v\in V$ y luego $r=s$ pues
	$(r-s)v=0$ para todo $v\in V$).

	\begin{claim}
		Si $U$ es un subespacio de $V$
		de dimensión finita, para cada $w\in V\setminus U$ existe $r\in R$ tal que
		$\gamma_r(U)=0$ y $\gamma_r(w)\ne0$.
	\end{claim}

	Supongamos que la afirmación no es cierta y sea $U$ un contraejemplo de la
	mínima dimensión posible. Entonces $\dim_DU\geq1$ (pues el resultado es
	cierto para el subespacio nulo). Sea $U_0$ un subespacio de $U$ tal que
	$\dim U_0=\dim U-1$ y sea
	\[
		L=\{l\in R:\gamma_l(U_0)=0\}.
	\]
	Como por la minimalidad de $U$ nuestra afirmación es cierta para $U_0$,
	para cualquier $v\in V\setminus U_0$ se tiene que $Lv=V$ (pues existe $l\in
	L$ tal que $lv=\gamma_l(v)\ne 0$, y como $L$ es ideal a izquierda de $R$ sabemos
	que $Lv\subseteq V$ es un submódulo y $V$ es simple).

	Sea $w\in V\setminus U$ tal que nuestra afirmación no es cierta y sea $u\in
	U\setminus U_0$.  La función 
	\[
		\delta\colon V\to V,\quad
		v\mapsto lw,
	\]
	donde $v=lu\in Lu=V$ (que depende de $u$ y $w$) 
	está bien definida: si $l_1,l_2\in L$ son tales que $v=l_1u=l_2u$ entonces $(l_1-l_2)u=0$ y luego
	\[
		0=\delta(0)=\delta((l_1-l_2)u)=(l_1-l_2)w=l_1w-l_2w. 
	\]
	Además $\delta$ es morfismo de $R$-módulos pues si $l\in L$ es tal que $v=lu$ entonces
	\[
		\delta(rv)=\delta(r(lu))=\delta( (rl)u)=(rl)w=r(lw)=r\delta(v)
	\]
	para todo $r\in R$.

	Para todo $l\in L$ se tiene que 
	\[
		l(\delta(u)-w)=l\delta(u)-lw=\delta(lu)-lw=0,
	\]
	y entonces $L(\delta(u)-w)=0$. Pero esto implica que $\delta(u)-w\not\in V\setminus U_0$, es
	decir $\delta(u)-w\in U_0$. Luego 
	\[
		w=xu-(xu-w)\in Du+U_0=U,
	\]
	una contradicción. 

	Esta afirmación alcanza para demostrar el teorema. En efecto, sean
	$u_1,\dots,u_n\in V$ vectores linealmente independientes y sean
	$v_1,\dots,v_n\in V$ vectores arbitrarios. Si fijamos $i\in\{1,\dots,n\}$, la afirmación anterior con
	\[
		U=\langle u_1,\dots,u_{i-1},u_{i+1},\dots,u_n\rangle
	\]
	y $w=u_i$ nos dice que existe $r_i\in R$ tal que $\gamma_{r_i}(u_j)=0$ si
	$j\ne i$ y $\gamma_{r_i}(u_i)\ne 0$. Como además existe $s_i\in R$ tal que
	$\gamma_{s_i}\gamma_{r_i}(u_i)=v_i$, se concluye que el elemento
	$r=\sum_{j=1}^n s_jr_j\in R$ es tal que $\gamma_r(u_i)=v_i$ para todo
	$i\in\{1,\dots,n\}$.
\end{proof}

%\begin{exercise}
%	Sea $R$ un anillo denso en $V$. Demuestre que $R$ es artiniano a izquierda
%	si y sólo si $V$ es de dimensión finita.
%\end{exercise}
% si V es de dimensión finita, es fácil por el lema~\ref{lem:unico_denso}
% hungerford pag 419

\begin{corollary}
	Si $R$ es un anillo primitivo, entonces existe un anillo de división $D$
	tal que $R\simeq\End_D(V)$ para algún $D$-espacio vectorial $V$ de
	dimensión finita, o bien para todo $m\in\Z_{>0}$ existe un subanillo $R_m$ de
	$R$ y un morfismo de anillos sobreyectivo $R_m\to\End_D(V_m)$ para algún $D$-espacio
	vectorial $V_m$ tal que $\dim_DV_m=m$.
\end{corollary}

\begin{proof}
	Sabemos que $R$ admite un módulo $V$ simple y fiel. Además, como $R$ es
	primitivo, por el teorema~\ref{thm:densidad} podemos suponer que existe un
	anillo de división $D$ tal que $R$ es denso en un $D$-espacio vectorial
	$V$.  Sea $\gamma\colon R\to\End_D(V)$, $r\mapsto\gamma_r$, donde
	$\gamma_r(v)=rv$. Como $V$ es fiel, $\gamma$ es inyectiva. Luego
	$R\simeq\gamma(R)$. 

	Si $V$ es de dimensión finita, el resultado se obtiene del
	lema~\ref{lem:unico_denso}.  Supongamos entonces que $V$ es de dimensión
	infinita y sea $\{u_1,u_2,\dots\}$ un conjunto linealmente independiente.
	Para cada $m\in\Z_{>0}$ sea $V_m$ el subespacio generado por $\{u_1,\dots,u_m\}$
	y sea $R_m=\{r\in R:rV_m\subseteq V_m\}$. Es fácil ver que $R_m$ es un
	subanillo de $R$. Como $R$ es denso en $V$, la función
	\[
		R_m\to \End_D(V_m),\quad
		r\mapsto\gamma_r|_{V_m}
	\]
	es un morfismo sobreyectivo de anillos. 
\end{proof}

%\section{El teorema de Wedderburn}

En álgebra conmutativa los dominios juegan un papel fundamental. En álgebra no
conmutativa las cosas no son tan similares ya que el anillo $M_n(K)$ no es un
dominio. Nos interesa entonces encontrar un concepto similar al de dominio que
funcione en el contexto no conmutativo.

\begin{definition}
	\index{Anillo!primo} 
	Sea $R$ un anillo (no necesariamente con unidad). Diremos que $R$ es
	\textbf{primo} si dados $x,y\in R$ tales que $xRy=0$ entonces $x=0$ o bien
	$y=0$.
\end{definition}

\begin{example}
	Recordemos que un anillo $R$ es un \textbf{dominio} si $xy=0$ implica que
	$x=0$ o bien $y=0$.  Todo dominio es trivialmente un anillo primo.
\end{example}

\begin{example}
	Un anillo conmutativo es primo si y sólo si es un dominio pues $ab=0$ si y
	sólo si $aRb=0$.
\end{example}

\begin{example}
	Un ideal no nulo de un anillo primo es un anillo primo.
\end{example}

\begin{lemma}
	Sea $R$ un anillo. Son equivalentes:
	\begin{enumerate}
		\item $R$ es primo.
		\item Si $I$ y $J$ son ideales a izquierda tales que $IJ=0$ entonces
			$I=0$ o bien $J=0$.
		\item Si $I$ y $J$ son ideales tales que $IJ=0$ entonces $I=0$ o bien
			$J=0$.
	\end{enumerate}
\end{lemma}

\begin{proof}
	Veamos primero que $(1)\implies(2)$. Sean $I$ y $J$ ideales a izquierda
	tales que $IJ=0$. Entonces $IRJ=I(RJ)\subseteq IJ=0$. Supongamos que $J\ne
	0$. Si $u\in I$ y $v\in J\setminus\{0\}$, entonces $uRv\in IRJ=0$ y luego
	$u=0$.

	La implicación $(2)\implies(3)$ es trivial. 

	Veamos entonces que $(3)\implies(1)$. Sean $x,y\in R$ tales que $xRy=0$.
	Sean $I=RxR$ y $J=RyR$. Como $IJ=(RxR)(RyR)=R(xRy)R=0$, por hipótesis,
	podemos suponer que entonces $I=0$. En particular $Rx$ y $xR$ son ideales
	pues $R(xR)=(Rx)R=0$. Pero entonces $\Z x$ es un ideal de $R$ tal que $(\Z x)R=0$. Luego $x=0$. 
\end{proof}

\begin{example}
	Todo anillo simple es trivialmente primo. La afirmación recíproca no es
	cierta: $\Z$ es un anillo primo (por ser un dominio) pero no es simple.
\end{example}

\begin{example}
	Si $R_1$ y $R_2$ son anillos, $R=R_1\times R_2$ no es primo pues
	$I=R_1\times 0$ y $J=0\times R_2$ son ideales no nulos tales que $IJ=0$.
\end{example}

\begin{lemma}
	\label{lem:primoizqmin=>prim}
	Sea $R$ un anillo primo y sea $L$ un ideal a izquierda minimal de $R$.
	Entonces $R$ es primitivo.
\end{lemma}

\begin{proof}
	Como $L$ es ideal a izquierda minimal, es simple como $R$-módulo. Veamos
	que como $R$ es primo, $L$ es fiel. Sea $y\in L\setminus\{0\}$ y sea
	$x\in\Ann_R(L)$.  Entonces, como $xRy\in xRL\subseteq xL=0$, se concluye
	que $x=0$.
\end{proof}

\begin{lemma}
	\label{lem:denso_artiniano}
	Sea $D$ un anillo de división y sea $R$ un anillo denso en un
	$D$-espacio vectorial $V$. Si $R$ es artiniano a izquierda, 
	entonces $V$ es de dimensión finita.
\end{lemma}

\begin{proof}
	Supongamos que $V$ tiene dimensión infinita y sea $\{u_1,u_2,\dots,\}$ un
	subconjunto de $V$ linealmente independiente. Como $R\subseteq\End_D(V)$,
	$V$ es un $R$-módulo con $f\cdot v=f(v)$, donde $f\in R$ y $v\in V$. Para
	cada $n\in\Z_{>0}$ sea 
	\[
		I_n=\Ann_R(\{u_1,\dots,u_n\}.
	\]
	Los $I_j$ son ideales a izquierda de $R$ tales que $I_1\supseteq
	I_2\supseteq\cdots\supseteq I_n\supseteq\cdots$. Veamos que esta sucesión
	no se estabiliza: Sean $n\in\Z_{>0}$ y $v\in V\setminus\{0\}$. Como $R$ es denso
	en $V$, existe $f\in R$ tal que $f(u_j)=0$ para todo $j\in\{1,\dots,n\}$ y
	$f(u_{n+1})=v\ne0$. Luego $I_1\supsetneq I_2\supsetneq\cdots\supsetneq
	I_n\supsetneq\cdots$, una contradicción pues $R$ es artiniano a izquierda.
\end{proof}

\begin{theorem}[Wedderburn]
	\index{Teorema!de Wedderburn}
	Sea $R$ un anillo artiniano a izquierda. Las siguientes afirmaciones son
	equivalentes:
	\begin{enumerate}
		\item $R$ es simple.
		\item $R$ es primo.
		\item $R$ es primitivo.
		\item $R\simeq M_n(D)$ para algún $n$ y algún anillo de división $D$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	La implicación $(1)\implies(2)$ es trivial. 
	
	Para demostrar que $(2)\implies(3)$ basta observar que como $R$ es
	artiniano, $R$ tiene un ideal a izquierda minimal.  Por el
	lema~\ref{lem:primoizqmin=>prim}, $R$ es primitivo. 

	Veamos que $(3)\implies(4)$. Si $R$ es primitivo, por el teorema de
	densidad de Jacbonson, existe un anillo de división $D$ tal que 
	$R$ es isomorfo a un anillo $S$ que es denso en un $D$-espacio vectorial
	$V$. Como $R$ es artiniano a izquierda, el lema~\ref{lem:denso_artiniano} implica que 
	$R=\End_D(V)\simeq M_n(D)$ pues $\dim_DV<\infty$. 

	Por último, $(4)\implies(1)$ es trivial pues $M_n(D)$ es simple. 
%	$D$-espacio vectorial $V$ de dimensión finita. Si $u_1,\dots,u_m\in V$ son
%	linealmente independientes sobre $D$, existen $f_1,\dots,f_m\in S$ tales
%	que $f_i(u_i)\ne0$ y $f_i(u_j)=0$ si $i\ne j$. Como los $f_j$ son
%	linealmente independientes sobre $k$, $\dim_DV\leq \dim A$. Luego $A=\End_DV\simeq M_n(D^{\op})$ 
%	por la proposición\dots
\end{proof}

Para completar nuestra presentación del teorema de Wedderburn, veremos
que la descomposición es única. Necesitaremos dos lemas previos:

\begin{lemma}
	\label{lem:wedderburn_unididad}
	Sea $D$ un anillo de división. Entonces 
	\[
		D^{\op}\simeq\End_{M_n(D)}(D^{n}). 
	\]
\end{lemma}

\begin{proof}
	Sea  
	\begin{align*}
		&\phi\colon D^{\op}\to\End_{M_n(D)}(D^{n}), & d\mapsto \phi(d)\colon &D^{n}\to D^{n},
	\end{align*}
	donde $\phi(d)(x)=xd$. Es evidente que $\phi$ es lineal; 
	es morfismo pues además 
	\begin{align*}
		\phi(d_1\cdot_{\op} d_2)(x)&=\phi(d_2d_1)(x)=x(d_2d_1)=(xd_2)d_1=\phi(d_1)\phi(d_2)(x).
	\end{align*}
	Como $\phi$ es no nulo y $D^{\op}$ es es simple por ser de división, se concluye que 
	$\phi$ es inyectivo. Veamos que
	$\phi$ es sobreyectivo: sean $f\in\End_{M_n(D)}(D^{n})$ y 
	\[
		e_1=\colvec{4}{1}{0}{\vdots}{0},\quad
		\colvec{4}{d_1}{d_2}{\vdots}{d_n}=
		f(e_1),
		\quad
		A=\begin{pmatrix} 
			a_1 & 0 & \cdots & 0\\
			\vdots & \vdots & \ddots & \vdots\\
			a_n & 0 & \cdots & 0
		\end{pmatrix}.
	\]
	Entonces
	\[
		f\colvec{4}{a_1}{a_2}{\vdots}{a_n}
		=f(Ae_1)=Af(e_1)=
		\colvec{4}{a_1d_1}{a_2d_2}{\vdots}{a_nd_1}=\phi(d_1)\colvec{3}{a_1}{\vdots}{a_n}.
	\]
\end{proof}

%%\begin{lemma}
%	\label{lem:Wedderburn:unicidad1}
%	Sea $D$ un anillo de división y sea $V$ un $D$-espacio vectorial de dimensión finita. 
%	Sea $R=\End_D(V)$. Si $M$ y $N$ son $R$-módulos 
%	simples y fieles, entonces $M\simeq N$.
%\end{lemma}
%
%\begin{proof}
%	Como $R=\End_D(V)\simeq M_n(D)$ es artiniano a izquierda, $R$ contiene un
%	ideal a izquierda minimal. Como $M$ es fiel, existe $m\in M$ tal que $Lm\ne
%	0$ (si $Lm=0$ para todo $m\in M$, $L\subseteq\Ann_R(M)=0$). Como $Lm$ es un
%	submódulo no nulo de $M$ y $M$ es simple, $Lm=M$. La función
%	\[
%		\theta\colon L\to Lm=M,\quad
%		x\mapsto xm
%	\]
%	es morfismo sobreyectivo. Como $L$ es simple como módulo, por el lema de
%	Schur, $\theta$ es inyectivo. Luego $L\simeq M$. Similarmente se demuestra
%	que $L\simeq N$.
%\end{proof}
%
%\begin{lemma}
%	\label{lem:Wedderburn:unicidad2}
%	Sea $D$ un anillo de división y sea $V$ un $D$-espacio vectorial. Sea
%	$g\colon V\to V$ un morfismo de grupos abelianos tal que $fg=gf$ para todo
%	$f\in\End_D(V)$. Entonces existe $d\in D$ tal que $g(v)=dv$ para todo $v\in
%	V$.
%\end{lemma}
%
%\begin{proof}
%	Sea $u\in V\setminus\{0\}$. Vamos a demostrar que $\{u,g(u)\}$ es
%	linealmente dependiente sobre $D$. Supongamos que $\{u,g(u)\}$ fuera linealmente
%	independiente. Entonces $\dim_DV\geq2$. 
%	Como $\End_D(V)$ es denso en $V$, existe $f\in\End_D(V)$ tal
%	que $f(u)=0$ y $f(g(u))\ne0$. Luego
%	\[
%		0\ne 0=f(g(u))=g(f(u))=g(0)=0,
%	\]
%	una contradicción.  Como $\{u,g(u)\}$ es linealmente dependiente sobre $D$,
%	existe $d\in D$ tal que $g(u)=du$. Si $v\in V$, por densidad existe
%	$h\in\End_D(V)$ tal que $h(u)=v$. Luego
%	\[
%		g(v)=g(h(u))=h(g(u))=h(du)=dh(u)=dv.
%	\]
%\end{proof}
%
%\begin{proposition}
%	Para cada $j\in\{1,2\}$ sea $V_j$ un espacio vectorial sobre el anillo de división $D_j$ de dimensión finita $n_j$. 
%	Si $\End_{D_1}(V_1)\simeq\End_{D_2}(V_2)$ entonces $n_1=n_2$ y $D_1\simeq D_2$.
%%	Sea $V$ es un espacio vectorial sobre el anillo de división $D$ y sea $W$
%%	un espacio vectorial sobre el anillo de división $E$. Supongamos que $V$ y
%%	$W$ son de dimensión finita. Si $\End_D(V)\simeq\End_E(W)$ entonces
%%	$\dim_DV=\dim_EW$ y $D\simeq E$.
%\end{proposition}
%
%\begin{proof}	
%	Cada $V_j$ es un $\End_{D_j}(V_j)$-módulo fiel. Sea $R=\End_{D_1}(V_1)$. Como existe un isomorfismo
%	$\sigma\colon R\to\End_{D_2}(V_2)$, $V_2$ es un
%	$R$-módulo simple y fiel con
%	\[
%		fv_2=\sigma(f)v_2,\quad
%		f\in R,\,v_2\in V_2.
%	\]
%	Por el lema~\ref{lem:Wedderburn:unicidad1}, existe un isomorfismo
%	$\phi\colon V_1\to V_2$ de $R$-módulos; en particular, 
%	\[
%		\phi(fv_1)=f(\phi(v_1))=(\sigma(f))\phi(v_1)
%	\]
%	para todo $v_1\in V_1$ y $f\in R$. Luego 
%	$\sigma(f)=\phi f\phi^{-1}\colon V_2\to V_2$ es un morfismo de grupos
%	abelianos. Para $j\in\{1,2\}$ y $d_j\in D_j$ sea 
%	\[
%		\gamma_{d_1}\colon V_j\to V_j,\quad x\mapsto d_jx.
%	\]
%	Como cada $V_j$ es fiel, $\gamma_{d_j}=0$ si y sólo si $d_j=0$. Si $f\in R$ y $d_1\in D_1$ entonces $f\gamma_{d_1}=\gamma_{d_1}f$. Luego
%	\[
%		(\phi\gamma_{d_1}\phi^{-1})\sigma(f)
%		=(\phi\gamma_{d_1}\phi^{-1})(\phi f\phi^{-1})
%		=\phi f\gamma_{d_1}\phi^{-1}
%		=\sigma(f)\phi\gamma_{d_1}\phi^{-1}.
%	\]
%	Como $\sigma$ es sobreyectiva, el lema~\ref{lem:Wedderburn:unicidad2} con
%	$V=V_2$ y $g=\phi\gamma_{d_1}\phi^{-1}$ implica que existe $d_2\in D_2$ tal
%	que $\phi\gamma_{d_1}\phi^{-1}=\gamma_{d_2}$. Sea $\tau\colon D_1\to D_2$,
%	$d_1\mapsto d_2$. Entonces $\phi\gamma_{d}\phi^{-1}=\gamma_{\tau(d_2)}$ 
%	\framebox{?}
%	Además 
%	\[
%		\phi(d_1v)=\phi\gamma_{d_1}(v)=\gamma_{\¿au(d_1)}\phi(v)=\tau_{d_1}\phi(v)
%	\]
%	Como $\{u_1,\dots,u_m\}$ es linealmente independiente sobre $D_1$ si y sólo si $\{\phi(u_1),\dots,\phi(u_m)\}$ es linealmente
%	independiente sobre $D_2$, se concluye que $\dim_{D_1}(V_1)=\dim_{D_2}(V_2)$. 
%\end{proof}

\begin{lemma}
	\label{lem:simple_izqminimal}
	Sea $R$ un anillo simple con un ideal a izquierda $L$ minimal. Entonces
	todo $R$-módulo simple es isomorfo a $L$. 
\end{lemma}

\begin{proof}
	Sea $M$ un módulo simple. Como $LR$ es un ideal de $R$ y el anillo $R$ es
	simple, $LR=R$.  Como
	\[
		0\ne RM=(LR)M=L(RM)\subseteq LM,
	\]
	existe $m\in M$ tal que $Lm\ne 0$. Luego $Lm$ es un submódulo no nulo del simple $M$ y entonces
	$Lm=M$. El morfismo $\gamma\colon L\to M$, $l\mapsto lm$, es sobreyectivo e
	inyectiva (pues $\ker\gamma$ es un ideal a izquierda propiamente
	contenido en $L$). Luego $L\simeq M$. 
\end{proof}

\begin{theorem}
	Si $D$ y $E$ son anillos de división tales que Si $M_n(D)\simeq M_m(E)$
	entonces $n=m$ y $D\simeq E$.
\end{theorem}

\begin{proof}
	Como $M_n(D)$ es artiniano a izquierda, existe 
	un ideal a izquierda $L$ minimal. Como
	$D^{n}\simeq E^{m}\simeq L$ como $M_n(D)$-módulos (ver ejemplo~\ref{exa:I_k}), 
	el lema~\ref{lem:simple_izqminimal} implica que
	\begin{align*}
		D^{\op}\simeq\End_{M_n(D)}(D^{n})\simeq\End_{M_n(D)}(L)\simeq\End_{M_m(E)}(L)\simeq\End_{M_m(E)}(E^{m})\simeq E^{\op}.
	\end{align*}
	Luego $D\simeq E$ y entonces $n=m$ pues $\dim M_n(D)=\dim M_m(E)$.
\end{proof}

%\section{El teorema de Connel}

Una pregunta surge naturalmente: ¿Cuándo el anillo de grupo $K[G]$ es primo?
Obtendremos una respuesta completa en el caso en que $K$ sea un cuerpo de
característica cero. 

%\begin{lemma}
%	\label{lemma:Dfg}
%	Sea $H$ un subgrupo finitamente generado de $\Delta(G)$.
%	\begin{enumerate}
%		\item $(G:C_G(H))$ es finito.
%		\item $(H:Z(H))$ es finito.
%		\item $[H,H]$ es finito.
%		\item Si $H_0$ es el conjunto de elementos de torsión de $H$, $H_0$ es
%			un subgrupo normal finito de $H$ y $H/H_0$ es finitamente generado,
%			abeliano y libre de torsión.
%	\end{enumerate}
%\end{lemma}
%
%\begin{proof}
%	Veamos la primera afirmación: Si $H=\langle
%	h_1,\dots,h_n\rangle\subseteq\Delta(G)$, entonces $(G:C_G(h_i))$ es finito
%	para todo $i\in\{1,\dots,n\}$. Como $C_G(H)=\cap_{i=1}^nC_G(h_i)$, se
%	concluye que $(G:C_G(H))$ es finito.
%
%	Para demostrar la segunda afirmación basta observar que $Z(H)=H\cap C_G(H)$
%	y luego $(H:Z(H))\leq(G:C_G(H)<\infty$. % necesito dos lemas
%
%	La tercera afirmación es consecuencia de la segunda gracias a un teorema de
%	Schur.
%
%	Por último, demostremos la cuarta afirmación.  El grupo $H/[H,H]$ es
%	abeliano y finitamente generado y luego, sus elementos de torsión forman un
%	grupo finito. Como $[H,H]$ es finito, $[H,H]$ es un subgrupo normal de
%	$H_0$. Vamos a demostrar que la torsión de $H/[H,H]$ es igual a
%	$H_0/[H,H]$. La inclusión $\supseteq$ es trivial. Veamos entonces que vale
%	$\subseteq$: so $(x[H,H])^k=1$, entonces $x^k\in[H,H]$. Luego $(x^k)^m=1$ y
%	luego $x\in H_0$. Tenemos entonces que 
%	\[
%		H/[H,H]\simeq\Z^r\times\operatorname{tor}(H/[H,H])\simeq\Z^r\times H_0/[H,H]
%	\]
%	y luego $H/H_0$ es finitamente generado, abeliano y libre de torsión.
%
%\end{proof}
%
%\begin{lemma}
%	\label{lemma:K[abelian]}
%	Si $G$ un grupo abeliano finitamente generado y sin torsión, entonces
%	$K[G]$ es un dominio. 
%\end{lemma}
%
%\begin{proof}
%	Por el teorema
%	de estructura de grupos abelianos finitamente generados podemos escribir
%	$G=\langle x_1\rangle\times\cdots\langle x_n\rangle$, donde
%	$\langle x_j\rangle\simeq\Z$ para todo $j\in\{1,\dots,n\}$. Todo elemento
%	de $G$ se escribe unívocamente como $x_1^{m_1}\cdots x_n^{m_n}$ y
%	luego la función 
%	\[
%		\iota\colon K[X_1,\dots,X_n]\to K[G],\quad
%		X_j\mapsto x_j,
%	\]
%	es un
%	morfismo de anillos inyectivo. Si $\alpha\in K[G]$, entonces existe
%	$m\in\N$ suficientemente grande tal que $\iota((X_1\cdots X_n)^m)\alpha\in
%	\iota(K[X_1,\dots,X_n])\simeq K[X_1,\dots,X_n]$. Luego $K[G]\subseteq
%	K(X_1,\dots,X_n)$ y $K[G]$ es un dominio.
%\end{proof}

%\begin{lemma}
%	Si $G$ es un grupo, entonces
%	$\Delta(G)/\Delta^+(G)$ es abeliano y libre de torsión.
%%	Valen las siguientes afirmaciones:
%%	\begin{enumerate}
%%		%\item $\Delta^+(G)$ está generado por los subgrupos normales finitos de $G$.
%%		\item 
%%		\item Si $\Delta^+(G)=1$, entonces $K[\Delta(G)]$ es un dominio.
%%	\end{enumerate}
%\end{lemma}
%
%\begin{proof}
%%	Demostremos la primera afirmación. 
%	Sean $y_1,\dots,y_n\in\Delta(G)$ y sea $L=\langle y_1,\dots,y_n\rangle$.
%	Como $[L,L]$ es finito por el lema~\ref{lemma:Dfg}, $[L,L]\subseteq\Delta^+(G)$. Luego
%	$\Delta(G)/\Delta^+(G)$ es abeliano y libre de torsión.
%%
%%	Para demostrar la segunda afirmación basta observar que si $\Delta^+(G)=1$
%%	entonces, por el primer ítem, $\Delta(G)$ es abeliano, finitamente generado
%%	y libre de torsión. Luego $K[\Delta(G)]$ es un dominio por el
%%	lema~\ref{lemma:K[abelian]}. 
%\end{proof}

Si $S$ es un subconjunto finito de un grupo $G$ se define
$\widehat{S}=\sum_{x\in S}x$. 

\begin{lemma}
	\label{lemma:sumN}
	Sea $N$ un subgrupo normal finito de $G$. Entonces $\widehat{N}$ es central
	en $K[G]$ y además $\widehat{N}(\widehat{N}-|N|1)=0$.
\end{lemma}

\begin{proof}
	Supongamos que $N=\{n_1,\dots,n_k\}$ y 
	sea $g\in G$. Como la función $N\to N$, $n\mapsto gng^{-1}$, es una biyección, 
	\[
		g\widehat{N}g^{-1}=g(n_1+\cdots+n_k)g^{-1}=gn_1g^{-1}+\cdots+gn_kg^{-1}=\widehat{N}.
	\]
	Como $nN=N$ si $n\in N$, se tiene que $n\widehat{N}=\widehat{N}$. Luego
	$\widehat{N}\widehat{N}=\sum_{j=1}^k n_j\widehat{N}=|N|\widehat{N}$.
\end{proof}

Necesitamos el siguiente teorema:

\begin{theorem}[Dietzmann]
	\index{Teorema!de Dietzmann}
	\label{theorem:Dietzmann} 
	Sea $G$ un grupo y sea $X\subseteq G$ un
	subconjunto finito de $G$ cerrado por conjugación. Si existe $n$ tal
	que $x^n=1$ para todo $x\in X$, entonces $\langle X\rangle$ es un subgrupo
	finito de $G$.
\end{theorem}

\begin{proof}
	Sea $S=\langle X\rangle$. Como $x^{-1}=x^{n-1}$, todo elemento de $S$ puede
	escribirse como producto (finito) de elementos de $X$. 
	
	Fijemos $x\in X$. Vamos a demostrar que si $x\in X$ aparece $k\geq 1$ veces
	en la representación de una palabra $s$, podemos escribir a $s$ como producto de $m$
	elementos de $X$ donde los primeros $k$ son iguales a $x$.  Supongamos que
	\[
	s=x_1x_2\cdots x_{t-1}xx_{t+1}\cdots x_m,
	\]
	donde cada $x_j\ne x$ para todo $j\in\{1,\dots,t-1\}$. Entonces
	\[
		s=x(x^{-1}x_1x)(x^{-1}x_2x)\cdots (x^{-1}x_{t-1}x)x_{t+1}\cdots x_m
	\]
	es producto de $m$ elementos de $X$ pues $X$ es cerrado por conjugación, y
	el primer elemento es nuestro $x$. Este mismo argumento implica que $s$
	puede escribirse como
	\[
		s=x^ky_{k+1}\cdots y_m,
	\]
	donde los $y_j$ son elementos de $X\setminus\{x\}$.

	Sea ahora $s\in S$ y escribamos a $s$ como producto de $m$ elementos de $X$,
	donde $m$ es el mínimo posible.  Para ver que $S$ es finito basta ver que 
	$m\leq (n-1)|X|$. 
	
	Si suponemos que $m>(n-1)|X|$, 
	al menos un $x\in X$ aparecería $n$ veces en la
	representación de $s$. Sin pérdida de generalidad, podríamos escribir 
	\[
		s=x^nx_{n+1}\cdots x_m=x_{n+1}\cdots x_m,
	\]
	una contradicción a la minimalidad de $m$. 
\end{proof}

Antes de seguir hacia nuestro objetivo demostraremos un teorema de Schur:

\begin{theorem}[Schur]
\index{Teorema!de Schur}
\label{thm:Schur}
	Si $Z(G)$ tiene índice finito en $G$ entonces $[G,G]$ es finito.
\end{theorem}

\begin{proof}
	Supongamos que $(G:Z(G))=n$. 
	Sea $X$ el conjunto de conmutadores de $G$. El conjunto $X$ es finito pues como la función
	\[
		\varphi\colon X\to G/Z(G)\times G/Z(G),\quad [x,y]\mapsto (xZ(G),yZ(G)),
	\]
	es inyectiva, se tiene que $|X|\leq n^2$. Para ver que $\varphi$ es
	inyectiva supongamos que $(xZ(G),yZ(G))=(uZ(G),vZ(G))$. Entonces $u^{-1}x\in Z(G)$, 
	$v^{-1}y\in Z(G)$ y luego 
	\begin{align*}
		[u,v]&=uvu^{-1}v^{-1}=uv(u^{-1}x)x^{-1}v^{-1}=xvx^{-1}(v^{-1}y)y^{-1}=xyx^{-1}y^{-1}=[x,y].
	\end{align*}
	Además $X$ es cerrado por conjugación pues
	\[
		g[x,y]g^{-1}=[gxg^{-1},gyg^{-1}]
	\]
	para todo $g,x,y\in G$. Como $g\mapsto g^n$ es un morfismo de grupos $G\to
	Z(G)$, lema~\ref{lem:center} implica que $[x,y]^n=[x^n,y^n]=1$ para todo
	$[x,y]\in X$.  Luego el teorema queda demostrado al aplicar el
	teorema~\ref{theorem:Dietzmann} de Dietzmann.
\end{proof}


Si $G$ es un grupo, consideramos el subconjunto %los siguientes subconjuntos:
\begin{align*}
%	&\Delta(G)=\{x\in G:(G:C_G(x))<\infty\},\\
	&\Delta^+(G)=\{x\in \Delta(G):\text{$x$ tiene orden finito}\}.
\end{align*}

\begin{lemma}
	\label{lem:DcharG}
	Si $G$ es un grupo, entonces $\Delta^+(G)$ es un subgrupo
	característico de $G$.
\end{lemma}

\begin{proof}
	Claramente $1\in\Delta^+(G)$. 
	Sean $x,y\in\Delta^+(G)$ y sea $H$ el subgrupo de $G$ generado por el
	conjunto $C$ formado por los finitos conjugados de $x$ e $y$. Si $|x|=n$ y
	$|y|=m$, entonces $c^{nm}=1$ para todo $c\in C$. Como $C$ es 
	finito y cerrado por conjugación, el teorema de Dietzmann implica que $H$ es
	finito. Luego $H\subseteq\Delta^+(G)$ y en particular $xy^{-1}\in\Delta^+(G)$.  Es
	evidente que $\Delta^+(G)$ es un subgrupo característico pues para todo
	$f\in\Aut(G)$ se tiene que $f(x)\in\Delta^+(G)$ si $x\in\Delta^+(G)$.
%	Primero veamos que $\Delta(G)$ es un subgrupo de $G$. Si $x,y\in\Delta(G)$
%	y $g\in G$, entonces $g(xy^{-1})g^{-1}=(gxg^{-1})(gyg^{-1})^{-1}$. Además
%	$1\in\Delta(G)$. Veamos ahora que $\Delta(G)$ es característico en $G$. Si
%	$f\in\Aut(G)$ y $x\in G$, entonces, como $f(gxg^{-1})=f(g)f(x)f(g)^{-1}$,
%	se concluye que $f(x)\in\Delta(G)$.
%	Para ver que $\Delta^+(G)$ es un subgrupo, 
%	Sean
%	$x_1,\dots,x_n\in\Delta^+(G)$ y $H=\langle x_1,\dots,x_n\rangle$. Como
%	$H$ es finito, $H\subseteq\Delta^+(G)$ y luego $\Delta^+(G)$ es un
%	subgrupo. Es evidente que es un subgrupo característico pues para todo
%	$f\in\Aut(G)$ se tiene que $f(x)\in\Delta^+(G)$ si $x\in\Delta^+(G)$.
\end{proof}

La segunda aplicación del teorema de Dietzmann es el siguiente resultado:

\begin{lemma}
	\label{lem:Connel}
	Sea $G$ un grupo y sea  $x\in\Delta^+(G)$.  Existe entonces un subgrupo
	finito $H$ normal en $G$ tal que $x\in H$.
\end{lemma}

Dejamos la demostración como ejercicio ya que el muy similar a lo que hicimos
en la demostración del lema~\ref{lem:DcharG}.

%\begin{proof}
%	Sea $H$ el subgrupo generado por los conjugados de $x$. Como $x$ tiene
%	finitos conjugados, $H$ es finitamente generado. Además $H$ es claramente
%	normal en $G$ y está generado por elementos de torsión. Todos los finitos
%	generadores de $H$ tienen el mismo orden, digamos $n$. Por el teorema de
%	Dietzmann, $H$ resulta ser un grupo finito.
%\end{proof}

\begin{theorem}[Connell]
	\label{thm:Connel}
	\index{Teorema!de Connel}
	Supongamos que el cuerpo $K$ es de característica cero. 
	Sea $G$ un grupo. Las siguientes afirmaciones son equivalentes:
	\begin{enumerate}
		\item $K[G]$ es primo.
		\item $Z(K[G])$ es primo.
		\item $G$ no tiene subgrupos finitos normales no triviales.
		\item $\Delta^+(G)=1$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Demostremos que $(1)\implies(2)$. Como $Z(K[G])$ es un anillo conmutativo,
	probar que es primo es equivalente a probar que no existen divisores de
	cero no triviales. Sean $\alpha,\beta\in Z(K[G])$ tales que
	$\alpha\beta=0$. Sean $A=\alpha K[G]$ y $B=\beta K[G]$. Como $\alpha$ y
	$\beta$ son centrales, $A$ y $B$ son ideales de $K[G]$. Como $AB=0$,
	entonces $A=\{0\}$ o $B=\{0\}$ pues $K[G]$ es primo.  Luego $\alpha=0$ o
	$\beta=0$.

	Demostremos ahora que $(2)\implies(3)$. Sea $N$ un subgrupo normal finito.
	Por el lema~\ref{lemma:sumN}, $\widehat{N}=\sum_{x\in N}x$ es central en
	$K[G]$ y $\widehat{N}(\widehat{N}-|N|1)=0$. Como $\widehat{N}\ne 0$ (pues
	$K$ tiene característica cero) y $Z(K[G])$ es un dominio,
	$\widehat{N}=|N|1$, es decir: $N=\{1\}$.

	Demostremos que $(3)\implies(4)$. Sea $x\in\Delta^+(G)$. Por el
	lema~\ref{lem:Connel} sabemos que existe un subgrupo finito $H$ normal en
	$G$ que contiene a $x$. Como por hipótesis $H$ es trivial, se concluye que
	$x=1$.

	Finalmente demostramos que $(4)\implies(1)$. Sean $A$ y $B$ ideales de
	$K[G]$ tales que $AB=0$. Supongamos que $B\ne 0$ y sea $\beta\in
	B\setminus\{0\}$.  Si $\alpha\in A$, entonces, como $\alpha
	K[G]\beta\subseteq \alpha B\subseteq AB=0$, el lema~\ref{lem:Passman} de
	Passman implica que $\pi_{\Delta(G)}(\alpha)\pi_{\Delta(G)}(\beta)=0$.
	Como por hipótesis $\Delta^+(G)$ es trivial, sabemos que $\Delta(G)$ es 
	libre de torsión y luego $\Delta(G)$ es abeliano por el
	lema~\ref{lem:FCabeliano}. Esto nos dice que $K[\Delta(G)]$ no tiene
	divisores de cero y luego $\alpha=0$. Demostramos entonces que $B\ne0$
	implica que $A=0$.
\end{proof}

% necesito: 
% pag 376 del Hungerford: un módulo no nulo admite una serie de composición
% si y sólo si es noetheriano y artiniano
% agregar además el teorema de Hopkins--Levitzky que dice


\begin{theorem}[Connel]
	Sea $K$ un cuerpo de característica cero y sea $G$ un grupo. Entonces
	$K[G]$ es artiniano a izquierda si y sólo si $G$ es finito.
\end{theorem}

\begin{proof}
	Si $G$ es finito, $K[G]$ es un álgebra de dimensión finita y luego
	es artiniano a izquierda. Supongamos entonces que $K[G]$ es artiniano
	a izquierda. 
	
	Primero observemos que si $K[G]$ es un álgebra prima, entonces por el
	teorema de Wedderburn $K[G]$ es simple y luego
	$G$ es el grupo trivial (pues si $G$ no es trivial, $K[G]$ no es simple ya
	que el ideal de aumentación es un ideal no nulo de $K[G]$).

	Como $K[G]$ es artiniano a izquierda, es noetheriano a izquierda por
	Hopkins--Levitzky y entonces, $K[G]$ admite una serie de composición por el
	teorema~\ref{thm:serie_de_composicion}.  Para demostrar el teorema
	procederemos por inducción en la longitud de la serie de composición de
	$K[G]$. Si la longitud es uno, $\{0\}$ es el único ideal de $K[G]$ y luego
	$K[G]$ es prima y el resultado está demostrado. Si suponemos que el
	resultado vale para longitud $n$ y además $K[G]$ no es prima, entonces, por
	el teorema de Connel, $G$ posee un subgrupo normal $H$ finito y no trivial. Al
	considerar el morfismo canónico $K[G]\to K[G/H]$ vemos que $K[G/H]$ es
	artiniano a izquierda y tiene longitud $<n$. Por hipótesis inductiva, $G/H$
	es un grupo finito y luego, como $H$ también es finito, $G$ es finito.
\end{proof}
